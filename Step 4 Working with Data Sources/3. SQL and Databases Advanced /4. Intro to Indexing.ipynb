{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 Working with Data Sources - Intro to Indexing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Introduction\n",
    "\n",
    "In previous missions, we've explored on how to query, modify, and create tables in a database. In this mission, we'll explore how queries are executed in SQLite. After exploring this at a high level, we explore how to create and use indexes for better performance. As our data gets larger and our queries more complex, it's important to be able to tweak the queries we write and optimize a database's schema to ensure that we're getting results back quickly.\n",
    "\n",
    "To explore database performance, we'll work with factbook.db, a SQLite database that contains information about each country in the world. We'll be working with the facts table in the database. Each row in facts represents a single country, and contains several columns, including:\n",
    "\n",
    "name -- the name of the country.\n",
    "area -- the total land and sea area of the country.\n",
    "population -- the population of the country.\n",
    "birth_rate -- the birth rate of the country.\n",
    "created_at -- the date the record was created.\n",
    "updated_at -- the date the record was updated.\n",
    "Here are the first few rows of facts:\n",
    "\n",
    "id\tcode\tname\tarea\tarea_land\tarea_water\tpopulation\tpopulation_growth\tbirth_rate\tdeath_rate\tmigration_rate\tcreated_at\tupdated_at\n",
    "1\taf\tAfghanistan\t652230\t652230\t0\t32564342\t2.32\t38.57\t13.89\t1.51\t2015-11-01 13:19:49.461734\t2015-11-01 13:19:49.461734\n",
    "2\tal\tAlbania\t28748\t27398\t1350\t3029278\t0.3\t12.92\t6.58\t3.3\t2015-11-01 13:19:54.431082\t2015-11-01 13:19:54.431082\n",
    "3\tag\tAlgeria\t2381741\t2381741\t0\t39542166\t1.84\t23.67\t4.31\t0.92\t2015-11-01 13:19:59.961286\t2015-11-01 13:19:59.961286\n",
    "Before we dive in further, let's set up our environment and explore the data.\n",
    "\n",
    "Instructions\n",
    "Write a query that returns the schema of the facts table and assign the resulting list of tuples to schema.\n",
    "Use a for loop and a print statement to display each tuple in schema on a separate line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect(\"factbook.db\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2. Query planner\n",
    "\n",
    "When you execute a SQL query, SQLite performs many steps before returning the results to you. First, it tokenizes and parses your query to look for any syntax errors. If there are any syntax errors, the query execution process halts and the error message is returned to you. If the parser was able to successfully parse the query, then SQLite moves on to the query planning and optimization phase.\n",
    "\n",
    "There are many different ways for SQLite to access the underlying data in a database. When working with a database that's stored on disk as a file, it's crucial to minimize the amount of disk reads necessary to avoid long running times. The query optimizer generates cost estimates for the various ways to access the underlying data, factoring in the schema of the tables and the operations the query requires. The heuristics and algorithms that are involved in query optimization is complex and out of this mission's scope.\n",
    "\n",
    "The optimizer quickly assesses the various ways to access the data and generates a best guess for the fastest query plan. This high level query plan is then converted into highly efficient, lower-level C code to interact with the database file on disk. Thankfully, we can observe the query plan to understand what SQLite is doing to return our results."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3. Explain query plan\n",
    "\n",
    "We can use the EXPLAIN QUERY PLAN statement before any query we're running to get a high level query plan that would be performed. If you write a SELECT statement and place the EXPLAIN QUERY PLAN statement before it:\n",
    "\n",
    "EXPLAIN QUERY PLAN SELECT * FROM facts;\n",
    "the results of the SELECT query won't be returned and instead the high level query plan will be:\n",
    "\n",
    "[(0, 0, 0, 'SCAN TABLE facts')]\n",
    "We'll focus on the value at index 4 in the returned tuple in this mission. SCAN TABLE means that every row in entire table (facts) had to be accessed to evaluate the query. Since the SELECT query we wrote returns all of the columns and rows in the facts table, the entire table had to be accessed to get the results we requested.\n",
    "\n",
    "When running the query using the sqlite3 library, you'll still need to use the fetchall() method or the query plan won't be returned:\n",
    "\n",
    "query_plan = conn.execute(\"EXPLAIN QUERY PLAN SELECT * FROM facts;\").fetchall()\n",
    "The query plan is represented as a tuple, which is the sqlite3 library's preferred way of representing results.\n",
    "\n",
    "Instructions\n",
    "Return the query plan for the query that returns all columns and rows where area exceeds 40000. Assign the results to query_plan_one.\n",
    "Return the query plan for the query that returns only the area column for all rows where area exceeds 40000. Assign the results to query_plan_two.\n",
    "Return the query plan for the query that returns the row for the country Czech Republic. Assign the results to query_plan_three.\n",
    "Use the print function to display each query plan."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4. Data representation\n",
    "\n",
    "You'll notice that all 3 query plans are exactly the same. The entire facts table had to be accessed to return the data we needed for all 3 queries. Even though all the queries asked for a subset of the facts table, SQLite still ends up scanning the entire table. Why is this? This is because of the way SQLite represents data.\n",
    "\n",
    "For the facts table, we set the id column as the primary key and SQLite uses this column to order the records in the database file. Since the rows are ordered by id, SQLite can search for a specific row based on it's id value using binary search. Unless we provide specific id values in the WHERE statement in the query, SQLite can't take advantage of binary search and has to instead scan the entire table, row by row. To return the results for the first 2 queries, SQLite has to:\n",
    "\n",
    "access the first row in the table (lowest id value),\n",
    "check if that row's value for area exceeds 40000 and store the row separately in a temporary collection if it is,\n",
    "move onto the next row,\n",
    "check if that row's value for area exceeds 40000 and store the row separately in a temporary collection if it is,\n",
    "repeat moving and checking each row for the rest of the table,\n",
    "return the final collection of rows that meet the criteria.\n",
    "Here's a diagram of what that looks like:\n",
    "\n",
    "If we were instead interested in a row with a specific id value, like in the following query:\n",
    "\n",
    "SELECT * FROM facts WHERE id=15;\n",
    "SQLite can use binary search to quickly find the corresponding row at that id value. Instead of performing a full table scan, SQLite would:\n",
    "\n",
    "use binary search to find the first row where the id value matches 15 in O(log N) time complexity and store this row in a temporary collection,\n",
    "advance to the next row to look for any more rows with the same id values and add those rows to the temporary collection,\n",
    "return the final collection of rows that matched.\n",
    "If we set the id column to be a UNIQUE PRIMARY KEY when we created the schema, SQLite would stop searching when it found the instances that matched the id value. It would avoid advancing to the next row(s) since no 2 rows could have the same id value. While we didn't enforce the UNIQUE constraint on the id column, all of the values currently in the column are in fact unique and SQLite will only have to advance one row to realize this since they're ordered.\n",
    "\n",
    "If you need a refresher on algorithmic complexity head to our mission on Algorithms. If you want to dive into binary search, check out our mission on Binary Search."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "5. Time complexity\n",
    "\n",
    "Binary search on a table using the primary key would be O(log N) time complexity where N is the number of total rows in the table. On the other hand, a full table scan would would be O(N) time complexity since each row would have to be accessed. If we're working with a database containing a millions rows, binary search would be over a million times faster! While you may not notice major performance differences when working with a small, on-disk database, they become profound as you scale up the amount of data you work with. Many organizations work with databases contains billions or trillions of rows and understanding the time complexity of queries is important to avoid writing queries that take a long time to complete.\n",
    "\n",
    "Let's now observe the query plan that SQLite takes to access a row at a specific id value.\n",
    "\n",
    "Instructions\n",
    "Return the query plan for the query that selects the row at id value 20 from the facts table.\n",
    "Assign the query plan to query_plan_four and display the query plan using the print function."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "6. Search and rowid\n",
    "\n",
    "Instead of using a full table scan:\n",
    "\n",
    "[(0, 0, 0, 'SCAN TABLE facts')]\n",
    "SQLite performed binary search on the facts table using the integer primary key:\n",
    "\n",
    "[(0, 0, 0, 'SEARCH TABLE facts USING INTEGER PRIMARY KEY (rowid=?)')]\n",
    "SQLite uses rowid to refer to the primary key of a table. The alias rowid will be displayed in the query plan, no matter what you name the primary key column for that table. Either SCAN or SEARCH will always appear at the start of the query explanation for SELECT queries."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "7. Indexing\n",
    "\n",
    "SQLite can take advantage of speedy lookups when searching for a specific primary key. Unfortunately, we don't always have the primary keys for the rows we're interested in beforehand. When we're expressing our intent as a SQL query, we're often thinking in terms of row and column values. We need to find a way that allows us to benefit from the speed of primary key lookups without actually knowing the primary key in advance.\n",
    "\n",
    "To that end, we could create a separate table that's optimized for lookups by a different column from the facts table instead of by the id. We can make the column we want to query by the primary key, so we get the speed benefits, and embed the id value from the facts table corresponding to that row. We call this table an index and each row in the index contains:\n",
    "\n",
    "the value we want to be able to search by, as the primary key,\n",
    "an id value for the corresponding row in facts.\n",
    "Let's walk through a concrete example. If we wrote a SELECT query to look up the population of India from the facts table:\n",
    "\n",
    "SELECT population FROM facts WHERE name = 'India';\n",
    "SQLite would need to perform a full table scan on facts to find the specific row where the value for name was India. We can instead create an index that's ordered by name values (primary key) and where each row contains the corresponding row's id from the facts table. Here's what that index would look like:\n",
    "\n",
    "We can write a query that uses the primary key, the country name, of the index table, which we'll call name_idx, to look up the row we're interested in and then extract the id value for that row in facts. Then, we can write a separate query that uses the id value returned from the previous query to look up the specific row in the facts table that contains information on India and then return just the population value.\n",
    "\n",
    "Instead of performing a single full table scan of facts, SQLite would perform a binary search on the index then another binary search on facts using the id value. Both queries are taking advantage of the primary key for the index and the facts table to quickly return the results we want. Here's a diagram of these concepts:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "8. Create an index\n",
    "\n",
    "Instead of creating a separate table and updating it ourselves, we can specify a column we want an index table for and SQLite will take care of the rest. SQLite, and most databases, make it easy for you to create indexes for tables on columns we plan to query often. To create an index we use the CREATE INDEX statement [https://www.sqlite.org/lang_createindex.html]. Here's the psuedo-code for that statement:\n",
    "\n",
    "CREATE INDEX index_name ON table_name(column_name);\n",
    "As you can see from the psuedo-code above, each index we create needs a name (to replace index_name). Similar to when you add a table to a database, using the IF NOT EXISTS clause helps you avoid attempting to create an index that already exists. Doing so will cause SQLite to throw an error. To create an index for the area column called area_idx, we write the following query:\n",
    "\n",
    "CREATE INDEX IF NOT EXISTS area_idx ON facts(area);\n",
    "An empty array will be returned when you run the query. The main benefit of having SQLite handle the maintenance of indexes we create is that the indexes are used automatically when we execute a query whenever there will be any speed advantages. As our queries become more complex, letting SQLite decide how and when to use the indexes we create helps us be much more productive.\n",
    "\n",
    "If we create an index for the area column in the facts table, SQLite will use the index whenever we search for rows in facts using that column. This index would be similar to the one we worked with in the past step and each row would only contain the area value and the corresponding row's id value. The index would be ordered by the area values for quick lookups.\n",
    "\n",
    "All three of the following queries would take advantage of the area_idx index:\n",
    "\n",
    "SELECT * FROM facts WHERE area = 10000;\n",
    "SELECT * FROM facts WHERE area > 10000;\n",
    "SELECT * FROM facts WHERE area < 10000;\n",
    "Since the area_idx index would be ordered by the area values, SQLite would:\n",
    "\n",
    "search for the first instance in the index where area equaled 10000 and store the id value in a temporary collection.\n",
    "it would then advance to the next row in the index to check if the WHERE condition was still met.\n",
    "if not, then the temporary collection would be returned and the process completes.\n",
    "if so, then SQLite would add that id value to the collection and check the next row.\n",
    "when SQLite finds a value for area that doesn't match the WHERE condition,\n",
    "it will look up and return the rows in facts using the id values stored in the temporary collection.\n",
    "each of these lookups will be O(log N) time complexity and while this could add up, it will still be faster than a full table scan.\n",
    "This process allows us to just write one query instead of 2 and have SQLite maintain and interact with the index. A table can have many indexes, and most tables in production environments usually do have many indexes. Every time you add or delete a row to the table, all of the indexes will be updated. If you edit the values in a row, SQLite will figure out which indexes are affected by the changes and update those indexes.\n",
    "\n",
    "While creating indexes gives us tremendous speed benefits, they come at the cost of space. Each index needs to be stored in the database file. In addition, adding, editing, and deleting rows takes longer since each of the affected indexes need to be updated. Since indexes can be created after a table is created, it's recommended to only create an index when you find yourself querying on a specific column frequently. Throughout the rest of the course, we'll explore how to understand the tradeoffs and you'll develop a better sense of how to create indexes in an optimal way.\n",
    "\n",
    "Now it's your turn to practice creating an index.\n",
    "\n",
    "Instructions\n",
    "Start psql.\n",
    "Create a user called aig with the following modifying statements:\n",
    "LOGIN\n",
    "PASSWORD 'test'\n",
    "SUPERUSER\n",
    "List all the users using \\du.\n",
    "Exit psql."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "9. All together now\n",
    "\n",
    "Instead of performing a full table scan on facts, SQLite used the name_idx index to return the id values first (in this case just one id value). Then, SQLite used binary search to extract just the rows from the facts table that corresponded to that id. SQLite utilized 2 binary searches instead of a full table scan to find the row corresponding to India.\n",
    "\n",
    "Let's now synthesize the concepts we learned in this mission to practice understanding the query plan and creating an index.\n",
    "\n",
    "Instructions\n",
    "Return the query plan for the query that returns all values in the rows in facts where the population exceeds 10000. Assign the resulting query plan to query_plan_six and display using the print function.\n",
    "Create an index for the population column in the facts table named pop_idx.\n",
    "Return the query plan for the query that returns all values in the rows in facts where the population exceeds 10000. Assign the resulting query plan to query_plan_seven and display using the print function."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "10. Next steps\n",
    "\n",
    "Instead of ending in USING INDEX pop_idx (population), the query plan ended in USING INDEX pop_idx (population>?). This is to indicate the granularity of the lookup that SQLite had to do for that index.\n",
    "\n",
    "In this mission, we explored how SQLite accessed data and how to create and take advantages of indexes. In the next mission, we'll learn how to create more complex indexes and dive deeper into database performance and learn about multi-column indices."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
