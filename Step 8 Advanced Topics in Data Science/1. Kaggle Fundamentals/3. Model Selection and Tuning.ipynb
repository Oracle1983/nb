{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8 Advanced Topics in Data Science - Model Selection and Tuning"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Introducing Model Selection\n",
    "\n",
    "In the previous mission, we worked to optimize our predictions by creating and selecting the features used to train our model. The other half of the optimization puzzle is to optimize the model itself— or more specifically, the algorithm used to train our model.\n",
    "\n",
    "So far, we've been using the logistic regression algorithm to train our models, however there are hundreds of different machine learning algorithms from which we can choose. Each algorithm has different strengths and weaknesses, and so we need to select the algorithm that works best with our specific data— in this case our Kaggle competition.\n",
    "\n",
    "The process of selecting the algorithm which gives the best predictions for your data is called model selection.\n",
    "\n",
    "In this mission, we're going work with two new algorithms: k-nearest neighbors and random forests.\n",
    "\n",
    "Before we begin, we'll need to import in the data. To save time, we have saved the features we created in the previous mission as CSV files, train_modified.csv and holdout_modified.csv.\n",
    "\n",
    "Instructions\n",
    "Import train_modified.csv into a pandas dataframe and assign the result to train.\n",
    "Import holdout_modified.csv into a pandas dataframe and assign the result to holdout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2. Training a Baseline Model\n",
    "\n",
    "We're going to train our models using all the columns in the train dataframe. This will cause a small amount of overfitting due to collinearity (as we discussed in the previous mission), but having more features will allow us to more thoroughly compare algorithms.\n",
    "\n",
    "So we have something to compare to, we're going to train a logistic regression model like in the previous two missions. We'll use cross validation to get a baseline score.\n",
    "\n",
    "Instructions\n",
    "Instantiate a linear_model.LogisticRegression class.\n",
    "Use the model_selection.cross_val_score() [http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html] function to train and test a model assigning the result to scores, using:\n",
    "The LogisticRegression object you just created\n",
    "all_X and all_y as the the X and y parameters\n",
    "10 folds\n",
    "Calculate the mean of scores and assign the result to accuracy_lr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "all_X = train.drop(['Survived','PassengerId'],axis=1)\n",
    "all_y = train['Survived']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3. Training a Model using K-Nearest Neighbors\n",
    "\n",
    "The logistic regression baseline model from the previous screen scored 82.4%.\n",
    "\n",
    "Model\tCross-validation score\tKaggle score\n",
    "Previous best Kaggle score\t82.3%\t78.0%\n",
    "Logistic regression baseline\t82.4%\t\n",
    "The logistic regression algorithm works by calculating linear relationships between the features and the target variable and using those to make predictions. Let's look at an algorithm that makes predictions using a different method.\n",
    "\n",
    "The k-nearest neighbors algorithm finds the observations in our training set most similar to the observation in our test set, and uses the average outcome of those 'neighbor' observations to make a prediction. The 'k' is the number of neighbor observations used to make the prediction.\n",
    "\n",
    "The plots below shows three simple k-nearest neighbors models where there are two features shown on each axis, and two outcomes, red and green.\n",
    "\n",
    "Simple k-nearest-neighbors classification algorithm\n",
    "https://s3.amazonaws.com/dq-content/187/knn_overview.svg\n",
    "\n",
    "In the first plot, the value of k is 1, so the closest 1 neighbour to our gray dot is used, green, making the prediction green.\n",
    "In the second plot, the value of k is 3, so the closest 3 neighbours to our gray dot are used, green, making the prediction red (2 red vs 1 green).\n",
    "In the third plot, the value of k is 5, so the closest 5 neighbours to our gray dot are used, green, making the prediction red (3 red vs 2 green).\n",
    "If you'd like to learn more about the k-nearest neighbors algorithm, you might like to check out our free Introduction to K-Nearest Neighbors mission.\n",
    "\n",
    "Just like it does for logistic regression, scikit-learn has a class that makes it easy to use k-nearest neighbors to make predictions, neighbors.KNeighborsClassifier.\n",
    "\n",
    "Scikit-learn's use of object-oriented design makes it easy to substitute one model for another. The syntax to instantiate a KNeighborsClassifier is very similar to the syntax we use for logistic regression.\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "The optional n_neighbors argument sets the value of k when predictions are made. The default value of n_neighbors is 5, but we're going to start by building a simple model that uses the closest neighbor to make our predictions.\n",
    "\n",
    "Instructions\n",
    "Instantiate a neighbors.KNeighborsClassifier object, setting the n_neighbors argument to 1.\n",
    "Use the model_selection.cross_val_score() function to train and test a model assigning the result to scores, using:\n",
    "The KNeighborsClassifier object you just created.\n",
    "all_X and all_y as the the X and y parameters.\n",
    "10 folds.\n",
    "Calculate the mean of scores and assign the result to accuracy_knn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4. Exploring Different K Values\n",
    "\n",
    "The k-nearest neighbors model we trained in the previous screen had an accuracy score of 78.6%, worse than our baseline score of 82.4%.\n",
    "\n",
    "Model\tCross-validation score\tKaggle score\n",
    "Previous best Kaggle score\t82.3%\t78.0%\n",
    "Logistic regression baseline\t82.4%\t\n",
    "K-nearest neighbors, k == 1\t78.6%\t\n",
    "Besides pure model selection, we can vary the settings of each model— for instance the value of k in our k-nearest neighbors model. This is called hyperparameter optimization.\n",
    "\n",
    "We can use a loop and Python's inbuilt range() class to iterate through different values for k and calculate the accuracy score for each different value. We will only want to test odd values for k to avoid ties, where both 'survived' and 'died' outcomes would have the same number of neighbors.\n",
    "\n",
    "This is the syntax we would use to get odd values between 1-7 from range():\n",
    "\n",
    ">>>  for k in range(1,8,2):\n",
    "...      print(k)\n",
    "     1\n",
    "     3\n",
    "     5\n",
    "     7\n",
    "Note that we use the arguments (1,8,2) to get values between 1 and 7, since the created range() object contains numbers up to but not including the 8.\n",
    "\n",
    "Let's use this technique to calculate the accuracy of our model for values of k from 1-49, storing the results in a dictionary.\n",
    "\n",
    "To make the results easier to understand, we'll finish by plotting the scores. We have provided a helper function, plot_dict() which you can use to easily plot the dictionary.\n",
    "\n",
    "Note that we expect this step to take a while to run, as we are training 250 models in total (10 cross validation models for each of 25 values of k).\n",
    "\n",
    "Instructions\n",
    "Use a for loop and the range class to iterate over odd values of k from 1-49, and in each iteration:\n",
    "Instantiate a KNeighborsClassifier object with the value of k for the n_neighbors argument.\n",
    "Use cross_val_score to create a list of scores using the newly created KNeighborsClassifier object, using all_X, all_y, and cv=10 as the arguments.\n",
    "Calculate the mean of the list of scores.\n",
    "Add the mean of the scores to the dictionary knn_scores, using k for the key.\n",
    "Use the plot_dict() helper function to plot the knn_scores dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_dict(dictionary):\n",
    "    pd.Series(dictionary).plot.bar(figsize=(9,6),\n",
    "                                   ylim=(0.78,0.83),rot=0)\n",
    "    plt.show()\n",
    "\n",
    "knn_scores = dict()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "5. Automating Hyperparameter Optimization with Grid Search\n",
    "\n",
    "Looking at our plot from the previous screen we can see that a k value of 19 gave us our best score, and checking the knn_scores dictionary we can see that the score was 82.4%, identical to our baseline (if we didn't round the numbers you would see that it's actually 0.01% less accurate).\n",
    "\n",
    "Model\tCross-validation score\tKaggle score\n",
    "Previous best Kaggle score\t82.3%\t78.0%\n",
    "Logistic regression baseline\t82.4%\t\n",
    "K-nearest neighbors, k == 1\t78.6%\t\n",
    "K-nearest neighbors, k == 19\t82.4%\t\n",
    "The technique we just used is called grid search - we train a number of models across a 'grid' of values and then searched for the model that gave us the highest accuracy.\n",
    "\n",
    "Scikit-learn has a class to perform grid search, model_selection.GridSearchCV(). The 'CV' in the name indicates that we're performing both grid search and cross validation at the same time.\n",
    "\n",
    "By creating a dictionary of parameters and possible values and passing it to the GridSearchCV object you can automate the process. Here's what the code from the previous screen would look like, when implemented using the GridSearchCV class.\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "​\n",
    "knn = KNeighborsClassifier()\n",
    "​\n",
    "hyperparameters = {\n",
    "    \"n_neighbors\": range(1,50,2)\n",
    "}\n",
    "grid = GridSearchCV(knn, param_grid=hyperparameters, cv=10)\n",
    "grid.fit(all_X, all_y)\n",
    "​\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "Running this code will produce the following output:\n",
    "\n",
    "{'n_neighbors': 19}\n",
    "0.82379349046\n",
    "Our final step was to print the GridSearchCV.best_params_ and GridSearchCV.best_score_ attributes to retrieve the parameters of the best-performing model, and the score it achieved.\n",
    "\n",
    "We can also use GridSearchCV to try combinations of different hyperparameters. Say we wanted to test values of \"ball_tree\", \"kd_tree\", and \"brute\" for the algorithm parameter and values of 1, 3, and 5 for the n_neighbors algorithm parameter. GridSearchCV would train and test 9 models (3 for the first hyperparameter times 3 for the second hyperparameter), shown in the diagram below.\n",
    "\n",
    "Grid Search\n",
    "https://s3.amazonaws.com/dq-content/187/gridsearch.svg\n",
    "\n",
    "Let's use GridSearchCV to turbo-charge our search for the best performing parameters for our model, by testing 40 combinations of three different hyperparameters.\n",
    "\n",
    "We have chosen the specific hyperparameters by consulting the documentation for the KNeighborsClassifier class.\n",
    "\n",
    "Instructions\n",
    "Instantiate a KNeighborsClassifier object.\n",
    "Instantiate a GridSearchCV object, using:\n",
    "The KNeighborsClassifier object you just created as the first (unnamed) argument\n",
    "The hyperparameters dictionary for the param_grid\n",
    "A cv of 10\n",
    "Fit the GridSearchCV object using all_X and all_y.\n",
    "Assign the parameters of the best performing model to best_params\n",
    "Assign the score of the of the best performing model to best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "hyperparameters = {\n",
    "    \"n_neighbors\": range(1,20,2),\n",
    "    \"weights\": [\"distance\", \"uniform\"],\n",
    "    \"algorithm\": ['brute'],\n",
    "    \"p\": [1,2]\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "6. Submitting K-Nearest Neighbors Predictions to Kaggle\n",
    "\n",
    "The cross-validation score for the best performing model was 82.8%, better than our baseline model.\n",
    "\n",
    "Model\tCross-validation score\tKaggle score\n",
    "Previous best Kaggle score\t82.3%\t78.0%\n",
    "Logistic regression baseline\t82.4%\t\n",
    "K-nearest neighbors, k == 1\t78.6%\t\n",
    "K-nearest neighbors, k == 19\t82.4%\t\n",
    "K-nearest neighbors, best model from grid search\t82.8%\t\n",
    "We can use the GridSearchCV.best_estimator_ attribute to retrieve a trained model with the best-performing hyperparameters. This code:\n",
    "\n",
    "best_knn = grid.best_estimator_\n",
    "is equivalent to this code where we manually specify the hyperparameters and train the model:\n",
    "\n",
    "best_knn = KNeighborsClassifier(p=1,algorithm='brute',n_neighbors=5,\n",
    "                     weights='uniform')\n",
    "best_knn.fit(all_X,all_y)\n",
    "Lets use that model to make predictions on the holdout set and submit those predictions to Kaggle to see if we have improved overall.\n",
    "\n",
    "Instructions\n",
    "Make predictions on the data from holdout_no_id using the best_knn model, and assign the result to holdout_predictions.\n",
    "Create a dataframe submission with two columns:\n",
    "PassengerId, with the values from the PassengerId column of the holdout dataframe.\n",
    "Survived, with the values from holdout_predictions.\n",
    "Use the DataFrame.to_csv method [https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html] to save the submission dataframe to the filename submission_1.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holdout_no_id = holdout.drop(['PassengerId'],axis=1)\n",
    "best_knn = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "7. Introducing Random Forests\n",
    "\n",
    "You can download the submission file from the previous screen here. [https://s3.amazonaws.com/dq-content/187/submission_1.csv]\n",
    "\n",
    "When you submit this toKaggle, you'll see it scores 75.6%, less than our best submission of 78.0%. While our model could be overfitting due to including all columns, it also seems like k-nearest neighbors may not be the best algorithm choice.\n",
    "\n",
    "Model\tCross-validation score\tKaggle score\n",
    "Previous best Kaggle score\t82.3%\t78.0%\n",
    "Logistic regression baseline\t82.4%\t\n",
    "K-nearest neighbors, k == 1\t78.6%\t\n",
    "K-nearest neighbors, k == 19\t82.4%\t\n",
    "K-nearest neighbors, best model from grid search\t82.8%\t75.6%\n",
    "Let's try another algorithm called random forests. Random forests is a specific type of decision tree algorithm. You have likely seen decision trees before as part of flow charts or infographics. Say we wanted to build a decision tree to help us categorize an object as either being 'hotdog' or 'not hotdog', we could construct a decision tree like the below:\n",
    "\n",
    "Decision Tree - Hotdog or Not Hotdog\n",
    "\n",
    "Decision tree algorithms attempt to build the most efficient decision tree based on the training data, and then use that tree to make future predictions. If you'd like to learn about decision trees and random forests in detail, you should check out our decision trees course.\n",
    "\n",
    "Scikit-learn contains a class for classification using the random forest algorithm, ensemble.RandomForestClassifier. Here's how to fit a model and make predictions using the RandomForestClassifier class:\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "​\n",
    "clf = RandomForestClassifier(random_state=1)\n",
    "clf.fit(train_X,train_y)\n",
    "predictions = clf.predict(test_X)\n",
    "Because the algorithm includes randomization, we have to set the random_state parameter to make sure our results are reproducible.\n",
    "\n",
    "Let's use a RandomForestClassifier object with cross_val_score() as we did earlier to see how the algorithm performs with the default hyperparameters.\n",
    "\n",
    "Instructions\n",
    "Instantiate a RandomForestClassifier object, setting the random_state parameter to 1.\n",
    "Use the cross_val_score() function to generate a set of scores and assign the result to scores, using:\n",
    "The RandomForestClassifer object you just created as the estimator\n",
    "all_X and all_y for the train and test data\n",
    "A cv value of 10\n",
    "Calculate the mean of scores and assign the result to accuracy_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "8. Tuning our Random Forests Model with GridSearch\n",
    "\n",
    "Using the default settings, our random forests model obtained a cross validation score of 80.7%.\n",
    "\n",
    "Model\tCross-validation score\tKaggle score\n",
    "Previous best Kaggle score\t82.3%\t78.0%\n",
    "Logistic regression baseline\t82.4%\t\n",
    "K-nearest neighbors, k == 1\t78.6%\t\n",
    "K-nearest neighbors, k == 19\t82.4%\t\n",
    "K-nearest neighbors, best model from grid search\t82.8%\t75.6%\n",
    "Random forests, default hyperparameters\t80.7%\t\n",
    "Just like we did with the k-nearest neighbors model, we can use GridSearchCV to test a variety of hyperparameters to find the best performing model.\n",
    "\n",
    "The best way to see a list of available hyperparameters is by checking the documentation for the classifier— in this case, the documentation for RandomForestClassifier [http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html]. Let's use grid search to test out combinations of the following hyperparameters:\n",
    "\n",
    "criterion: \"entropy\" or \"gini\"\n",
    "max_depth: 5 or 10\n",
    "max_features: \"log2\" or \"sqrt\"\n",
    "min_samples_leaf: 1 or 5\n",
    "min_samples_split: 3 or 5\n",
    "n_estimators: 6 or 9\n",
    "\n",
    "Instructions\n",
    "Instantiate a RandomForestClassifer object, setting the random_state parameter to 1.\n",
    "Instantiate a GridSearchCV object, using:\n",
    "The RandomForestClassifer object you just created as the first (unnamed) argument\n",
    "A dictionary of hyperparameters that matches the list above for the param_grid argument\n",
    "A cv of 10.\n",
    "Fit the GridSearchCV object using all_X or all_y.\n",
    "Assign the parameters of the best performing model to best_params\n",
    "Assign the score of the of the best performing model to best_score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "9. Submitting Random Forest Predictions to Kaggle\n",
    "\n",
    "The cross-validation score for the best performing model was 84.3%, making it the best cross-validation score we've obtained in this mission.\n",
    "\n",
    "Model\tCross-validation score\tKaggle score\n",
    "Previous best Kaggle score\t82.3%\t78.0%\n",
    "Logistic regression baseline\t82.4%\t\n",
    "K-nearest neighbors, k == 1\t78.6%\t\n",
    "K-nearest neighbors, k == 19\t82.4%\t\n",
    "K-nearest neighbors, best model from grid search\t82.8%\t75.6%\n",
    "Random forests, default hyperparameters\t80.7%\t\n",
    "Random forests, best model from grid search\t84.3%\t\n",
    "Let's train it on the holdout data and create a submission file to see how it performs on the Kaggle leaderboard!\n",
    "\n",
    "Instructions\n",
    "Assign the best performing model from the GridSearchCV object grid to best_rf.\n",
    "Make predictions on the data from holdout_no_id using the best_rf model, and assign the result to holdout_predictions.\n",
    "Create a dataframe submission with two columns:\n",
    "PassengerId, with the values from the PassengerId column of the holdout dataframe.\n",
    "Survived, with the values from holdout_predictions.\n",
    "Use the DataFrame.to_csv method to save the submission dataframe to the filename submission_2.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The `GridSearchCV` object is stored in memory from\n",
    "# the previous screen with the variable name `grid`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "10. Next Steps\n",
    "\n",
    "The submission file we created in the previous step is available for download here. [https://s3.amazonaws.com/dq-content/187/submission_2.csv]\n",
    "\n",
    "Submission Rank\n",
    "If you submit this to Kaggle, it achieves a score of 77.1%, considerably better than our k-nearest neighbors score of 75.6% and very close (2 incorrect predictions) to our best score from the previous mission of 78.0%\n",
    "\n",
    "Model\tCross-validation score\tKaggle score\n",
    "Previous best Kaggle score\t82.3%\t78.0%\n",
    "Logistic regression baseline\t82.4%\t\n",
    "K-nearest neighbors, k == 1\t78.6%\t\n",
    "K-nearest neighbors, k == 19\t82.4%\t\n",
    "K-nearest neighbors, best model from grid search\t82.8%\t75.6%\n",
    "Random forests, default hyperparameters\t80.7%\t\n",
    "Random forests, best model from grid search\t84.3%\t77.1%\n",
    "By combining our strategies for feature selection, feature engineering, model selection and model tuning, we'll be able to continue to improve our score.\n",
    "\n",
    "The next and final mission in this course is a guided project, where we'll teach you how to combine everything you've learned into a real-life Kaggle workflow, and continue to improve your score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
