{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 The Command Line - Guided Project Working with Data Downloads"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Introduction\n",
    "\n",
    "Almost all of the data you work with as a data scientist will come from a remote source, such as another website on the Internet. File downloads sometimes come in analysis-ready formats like CSV. At other times, the data will be in an archive format like TAR or ZIP. These formats compress files to reduce overall size, which makes them faster to download. Archive formats can also bundle multiple data files into a single archive file.\n",
    "\n",
    "In this guided project, we'll be working with an education data set in ZIP format. We'll learn how to extract the files inside the ZIP download and then work with them.\n",
    "\n",
    "You may have noticed that the interface for this guided project is a bit different. There's a terminal at the bottom, where you'll be running commands. There's also an editor at the top, where you can edit files like Python scripts. The file browser on the left allows you to view folders and open files for editing.\n",
    "\n",
    "Interface\n",
    "\n",
    "The data set we'll work with is called the Civil Rights Data Collection. It contains information on educational achievement and opportunities in the U.S., broken down by race and school. For example, it records the racial composition of the students enrolled in advanced classes at each school. Each row represents a school, while each column records an indicator of academic achievement.\n",
    "\n",
    "For the purposes of this exercise, we'll be using a subset of the data that only contains 1 out of every 100 rows in the original data set. If you'd like to work with the original version, you can download it from data.gov. [https://catalog.data.gov/dataset/civil-rights-data-collection-2013-14]\n",
    "\n",
    "Here are the first few rows:\n",
    "\n",
    "LEA_STATE\tLEA_NAME\tSCH_NAME\tCOMBOKEY\tLEAID\tSCHID\tJJ\tCCD_LATCOD\tCCD_LONCOD\tNCES_SCHOOL_ID\t...\tSCH_FTE_TEACH_WOFED\tSCH_SAL_TEACH_WOFED\tSCH_NPE_WOFED\tDSO_SCH_FTE_TEACH_WOFED\tDSO_SCH_NPE_WOFED\tDSO_SCH_SAL_INSTR_WOFED\tDSO_SCH_SAL_TEACH_WOFED\tSCH_JJTYPE\tSCH_JJSYDAYS\tSCH_JJHOURS\n",
    "0\tTX\tDENTON ISD\tRYAN EL\t481674008530\t4816740\t8530\tNO\t33.1604\t-97.1354\t4.816740e+11\t...\t39.00\t2274986.15\t316158.74\t0\t0\t0\t0\t-9\t-9\t-9\n",
    "1\tLA\tLAFAYETTE PARISH\tJUDICE MIDDLE SCHOOL\t220087000675\t2200870\t675\tNO\t30.1673\t-92.1403\t2.200870e+11\t...\t32.95\t1585446.66\t32769.37\t0\t0\t0\t0\t-9\t-9\t-9\n",
    "2\tGA\tHENRY COUNTY\tEAGLE'S LANDING MIDDLE SCHOOL\t130282000399\t1302820\t399\tNO\t33.4885\t-84.2086\t1.302820e+11\t...\t48.18\t2294195.77\t0.00\t0\t0\t0\t0\t-9\t-9\t-9\n",
    "3\tFL\tMONROE\tKEYS CENTER\t120132007521\t1201320\t7521\tNO\t24.5638\t-81.7980\t1.201320e+11\t...\t1.00\t61369.15\t34275.00\t0\t0\t0\t0\t-9\t-9\t-9\n",
    "4\tOH\tCLARK-SHAWNEE LOCAL\tPOSSUM ELEMENTARY SCHOOL\t390462802499\t3904628\t2499\tNO\t39.8864\t-83.8388\t3.904628e+11\t...\t14.02\t840251.25\t616504.50\t0\t0\t0\t0\t-9\t-9\t-9\n",
    "5 rows × 1929 columns\n",
    "Before we can load and analyze the data, we'll need to extract the files that contain it from the archive file, crdc201314csv.zip. We can call the unzip command on an archive file to extract the files within it. Here's an example:\n",
    "\n",
    "unzip test.zip\n",
    "This command will extract all of the files from the archive test.zip into the current directory. Once we've extracted the files inside an archive file, it's good practice to delete the original archive to save space.\n",
    "\n",
    "Instructions\n",
    "List the contents of the current directory with the ls command, and take note of the archive file crdc201314csv.zip.\n",
    "Extract the files in crdc201314csv.zip using the unzip command.\n",
    "List the contents of the current directory, and make sure there are 4 new data files.\n",
    "Delete crdc201314csv.zip."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2. Running a Python Script to Explore the Columns\n",
    "\n",
    "Because the data set has more than 2000 columns, there's a separate file that explains what each column means. The explanatory file (or \"data dictionary\") is CRDC2013_14content.csv, while the data file itself is CRDC2013_14.csv.\n",
    "\n",
    "We'll need to create a Python script, load CRDC2013_14content.csv using pandas, and then decide on a few columns to explore in greater depth.\n",
    "\n",
    "Recall that in order to run a script from the command line, we'll need to create a few lines of code and save them as a file. Let's say the following lines are already in a file called read.py:\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Program executed successfully!\")\n",
    "We could then run that script by typing python read.py on the command line.\n",
    "\n",
    "We'll have to run our Python script using a virtual environment that has a pandas installation on it. The virtual environment we need to activate is in the /dataquest/system/env/python3 folder. As you may recall from a previous mission, we'll need to run source /dataquest/system/env/python3/bin/activate to activate the virtual environment.\n",
    "\n",
    "Instructions\n",
    "Activate the python3 virtual environment.\n",
    "Run pip freeze to verify that pandas is installed and available.\n",
    "Edit read.py so that it will run from the command line.\n",
    "Add code to read.py to:\n",
    "Import pandas.\n",
    "Read CRDC2013_14content.csv into a pandas dataframe called contents.\n",
    "Print the first few rows of contents.\n",
    "Run read.py from the terminal, and verify that it worked properly.\n",
    "Continue exploring the contents dataframe to find any column names that interest you."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3. Using Pandas to Find Patterns in the Data\n",
    "\n",
    "Now that we've looked at the column names more closely, here are some potentially interesting ones that popped out:\n",
    "\n",
    "JJ - Indicates whether the school is part of a juvenile justice facility, or youth prison.\n",
    "SCH_STATUS_MAGNET - Indicates whether the school is a magnet school, an advanced school for students who achieve high scores on certain tests.\n",
    "We can dig around for interesting patterns here by using Series.value_counts() [http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.value_counts.html] to find unique values in each column. This will tell us how many schools are juvenile justice facilities or magnet schools.\n",
    "\n",
    "We can also count how many students are in juvenile justice facilities by using the pandas.pivot_table() [http://pandas.pydata.org/pandas-docs/stable/generated/pandas.pivot_table.html] function to create a pivot table. Building a pivot table will allow us to aggregate TOT_ENR_M and TOT_ENR_F (which record school enrollment by gender) by JJ and SCH_STATUS_MAGNET. This will count up how many students are in magnet schools or juvenile justice facilities.\n",
    "\n",
    "The Python code below, for example, will create a pivot table that counts the total number of male and female students in juvenile justice facilities:\n",
    "\n",
    "import pandas as pd\n",
    "​\n",
    "pd.pivot_table(data, values=[\"TOT_ENR_M\", \"TOT_ENR_F\"], index=\"JJ\", aggfunc=\"sum\")\n",
    "\n",
    "Instructions\n",
    "Create a new file called exploration.py that you can run from the command line.\n",
    "In exploration.py:\n",
    "Read CRDC2013_14.csv into a pandas dataframe called data.\n",
    "Be sure to specify the keyword argument encoding=\"Latin-1\" so that pandas reads the file in properly.\n",
    "Call the value_counts method on the JJ and SCH_STATUS_MAGNET columns to count the number of schools that fall within each category.\n",
    "Print out the results so you see them when you run the script.\n",
    "Execute exploration.py.\n",
    "In exploration.py:\n",
    "Construct two pivot tables that aggregate TOT_ENR_M and TOT_ENR_F based on JJ and SCH_STATUS_MAGNET.\n",
    "Print out the results so you see them when you run the script.\n",
    "Execute exploration.py.\n",
    "Create a text file called findings.txt that summarizes any interesting patterns you observe."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4. Using Pandas to Explore Enrollment by Race\n",
    "\n",
    "Several of the columns in our data break school attributes down by race and gender. The names of these columns begin with an abbreviation for the attribute name. SCH_ENR stands for \"school enrollment,\" for example. Next, they include a code name for race, such as HP. The last part is a code name for gender, which is eitherF or M. For example, the complete name for the column that records hispanic female enrollment is SCH_ENR_HI_F.\n",
    "\n",
    "Here are the code names for each race:\n",
    "\n",
    "HI - Hispanic\n",
    "AM - American Indian\n",
    "AS - Asian\n",
    "HP - Hawaiian or Pacific Islander\n",
    "BL - Black\n",
    "WH - White\n",
    "TR - Two or more races\n",
    "Here are the gender code names:\n",
    "\n",
    "F - Female\n",
    "M - Male\n",
    "The data set contains one column for every possible combination of racial and gender code names associated with an attribute -- that's why there are more than 2,000 columns!\n",
    "\n",
    "Here's a list of all of the columns that indicate school enrollment, for example:\n",
    "\n",
    "SCH_ENR_HI_M\n",
    "SCH_ENR_HI_F\n",
    "SCH_ENR_AM_M\n",
    "SCH_ENR_AM_F\n",
    "SCH_ENR_AS_M\n",
    "SCH_ENR_AS_F\n",
    "SCH_ENR_HP_M\n",
    "SCH_ENR_HP_F\n",
    "SCH_ENR_BL_M\n",
    "SCH_ENR_BL_F\n",
    "SCH_ENR_WH_M\n",
    "SCH_ENR_WH_F\n",
    "SCH_ENR_TR_M\n",
    "SCH_ENR_TR_F\n",
    "There are also two columns that indicate total enrollment by gender:\n",
    "\n",
    "TOT_ENR_M - Total male enrollment\n",
    "TOT_ENR_F - Total female enrollment\n",
    "Several other column names combine race and gender codes, including:\n",
    "\n",
    "SCH_HBREPORTED_DIS - Students who report being harrased or bullied\n",
    "SCH_DISCWODIS_EXPWOE - Students without disabilities who were expelled from school\n",
    "SCH_RET_G12 - Students who started and completed grade 12\n",
    "\n",
    "Instructions\n",
    "Create a new file called enrollment.py that will run from the command line.\n",
    "In enrollment.py:\n",
    "Read in the data file using pandas.\n",
    "Create a column called total_enrollment that adds the TOT_ENR_M and TOT_ENR_F columns.\n",
    "Compute the sums of all of the columns that break down enrollment by race and gender.\n",
    "Compute the sum of the total_enrollment column, and assign the result to the variable all_enrollment.\n",
    "Divide the sums of the columns by all_enrollment to determine the percentage of enrollment that each race and gender makes up.\n",
    "Print out the results.\n",
    "Run enrollment.py.\n",
    "Compare the results to the overall population of the United States, broken down by race and gender. You can find the data on race at Wikipedia's U.S. race demography page [https://en.wikipedia.org/wiki/Demography_of_the_United_States#Race_and_ethnicity], and the data on gender at Wikipedia's U.S. sex ratios page [https://en.wikipedia.org/wiki/Demography_of_the_United_States#Sex_ratios].\n",
    "To make the analysis simpler, you can assume that the gender ratio in the U.S. is 1:1.\n",
    "Add any interesting patterns you've found to findings.txt."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "5. Moving the Data Files to a Separate Folder\n",
    "\n",
    "When we're working with data files, it's common to put them in a folder named data. This makes it easy to separate our scripts and findings from the source data. In cases where the source data is several hundred megabytes, it also makes it easier to share our code and findings only.\n",
    "\n",
    "In order to do this, we'll need to create a folder, then move the data files into it. Finally, we'll need to rewrite our Python scripts so that they load the data files in that folder.\n",
    "\n",
    "Instructions\n",
    "Create a folder called data inside the current folder.\n",
    "Move the data files to the data folder. These include:\n",
    "CRDC_documentation_csv.txt\n",
    "CRDC_usage_agreement.txt\n",
    "CRDC2013_14.csv\n",
    "CRDC2013_14content.csv\n",
    "Edit read.py, exploration.py, and enrollment.py so that they access the files inside the data folder."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "6. Next Steps\n",
    "\n",
    "Now that you've read in the files and found some interesting columns, you can dig in and analyze the data more. There are quite a few interesting angles you could explore:\n",
    "\n",
    "Review expulsions (which refers to when students are kicked out of school permanently). Columns like SCH_DISCWODIS_EXPWOE_HI_M and TOT_DISCWODIS_EXPZT_F contain information on expulsions.\n",
    "Explore gender and race differences in SAT scores. Columns like SCH_SATACT_HI_M contain this information.\n",
    "Figure out the racial and gender breakdowns for different types of schools, such as magnet schools.\n",
    "Determine how many students are in gifted and talented programs, or advanced placement classes.\n",
    "Investigate how racial differences in enrollment change from preschool to high school.\n",
    "Explore school bullying. The SCH_HBDISCIPLINED_DIS_HI_M column contains some of this information.\n",
    "We recommend that you download these files and work on your own machine. We also recommend that you download the full data set from data.gov [https://catalog.data.gov/dataset/civil-rights-data-collection-2013-14]. If you find anything interesting while exploring the data, please let us know!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
