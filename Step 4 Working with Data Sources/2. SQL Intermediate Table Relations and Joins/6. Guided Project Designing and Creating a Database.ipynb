{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 Working with Data Sources - Guided Project Designing and Creating a Database"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Getting to Know the Data\n",
    "\n",
    "In this guided project, we're going to learn how to:\n",
    "\n",
    "Import data into SQLite\n",
    "Design a normalized database schema\n",
    "Create tables for our schema\n",
    "Insert data into our schema\n",
    "\n",
    "We will be working with a file of Major League Baseball [https://en.wikipedia.org/wiki/Major_League_Baseball] games from Retrosheet[http://www.retrosheet.org/]. Retrosheet compiles detailed statistics on baseball games from the 1800s through to today. The main file we will be working from game_log.csv, has been produced by combining 127 separate CSV files from retrosheet, and has been pre-cleaned to remove some inconsistencies. The game log has hundreds of data points on each game which we will normalize this data into several separate tables using SQL, providing a robust database of game-level statistics.\n",
    "\n",
    "In addition to the main file, we have also included three 'helper' files, also sourced from Retrosheet:\n",
    "\n",
    "park_codes.csv\n",
    "person_codes.csv\n",
    "team_codes.csv\n",
    "These three helper files in some cases contain extra data, but will also make things easier as they will form the basis for three of our normalized tables.\n",
    "\n",
    "An important first step when working with any new data is to perform exploratory data analysis (EDA). EDA gets us familiar with the data and gives us a level of background knowledge that will help us throughout our project. The methods you use when performing EDA will depend on what you plan to do with the data. In our case, we're wanting to create a normalized database, so our focus should be:\n",
    "\n",
    "Becoming familiar, at a high level, with the meaning of each column in each file.\n",
    "Thinking about the relationships between columns within each file.\n",
    "Thinking about the relationships between columns across different files.\n",
    "We have included a game_log_fields.txt file from Retrosheet which explains the fields included in our main file, which will be useful to assist our EDA. You can use !cat game_log_fields.txt in its own Jupyter cell to read the contents of the file.\n",
    "\n",
    "If you're not familiar with baseball some of this can seem overwhelming at first, however this presents a great opportunity. When you are working with data professionally, you'll often encounter data in an industry you might be unfamiliar with - it might be digital marketing, geological engineering or industrial machinery. In these instances, you'll have to perform research in order to understand the data you're working with.\n",
    "\n",
    "Baseball is a great topic to practice these skills with. Because of the long history within baseball of the collection and analysis of statistics (most famously the Sabermetrics featured in the movie Moneyball), there is a wide range of online resources available to help you get answers to any questions you may have.\n",
    "\n",
    "Let's get started exploring the data by using pandas to read and explore the data. Setting the following options after you import pandas is recommended– they will prevent the DataFrame output from being truncated, given the size of the main game log file:\n",
    "\n",
    "pd.set_option('max_columns', 180)\n",
    "pd.set_option('max_rows', 200000)\n",
    "pd.set_option('max_colwidth', 5000)\n",
    "\n",
    "Instructions\n",
    "Using pandas, read in each of the four CSV files: game_log.csv, park_codes.csv, person_codes.csv, team_codes.csv. For each:\n",
    "Use methods and attributes like DataFrame.shape, DataFrame.head(), and DataFrame.tail() to explore the data.\n",
    "Write a brief paragraph to describe each file, including for the helper files how the data intersects with the main log file.\n",
    "Research any fields you are not familiar with, using both the text file and Google as needed. In particular, you should explore and write a short paragraph on:\n",
    "What each defensive position number represents.\n",
    "The values in the various league fields, and which leagues they represent."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2. Importing Data into SQLite\n",
    "\n",
    "To insert data into a noramalized database, we'll need a single column that can be used as a primary key. The game log file does not have a single column that can be used as a primary key to uniquely identify each game. There are three ways that we could handle this:\n",
    "\n",
    "Make a compound primary key, such as a primary key of the date, h_name, and number_of_game columns.\n",
    "Insert an integer primary key, eg where the first row is 1, the second row is 2, etc.\n",
    "Insert a new column using a custom format.\n",
    "Because we have not yet normalized our data, it's better not to start with a compound primary key - if we do this, we might end up needing to create a compound key in another table that includes this compound key, which would quickly become cumbersome to work with. An integer primary key is a good choice, but we should first explore whether Retrosheet already have a system for uniquely identifying each game. If they do, this is a better option. It means that if at some later stage we choose to incorporate more detailed game data into our database, the keys we use will be compatible with other sources.\n",
    "\n",
    "Exploring the Retrosheet site, we can find this data dictionary [http://www.retrosheet.org/eventfile.htm] for their event files, which list every event within each game. This includes the following description:\n",
    "\n",
    "id: Each game begins with a twelve character ID record which identifies the date, home team, and number of the game. For example, ATL198304080 should be read as follows. The first three characters identify the home team (the Braves). The next four are the year (1983). The next two are the month (April) using the standard numeric notation, 04, followed by the day (08). The last digit indicates if this is a single game (0), first game (1) or second game (2) if more than one game is played during a day, usually a double header The id record starts the description of a game thus ending the description of the preceding game in the file.\n",
    "\n",
    "You might notice that this essentially makes a custom key using the three columns we identified in our composite key example earlier. After we import the data, we'll construct this column to use as a primary key in our final database.\n",
    "\n",
    "Our next task is to import the data into SQLite. There are three key ways to import data into a SQLite database:\n",
    "\n",
    "1. Using the Python SQLite library\n",
    "\n",
    "The Python SQLite library [https://docs.python.org/3/library/sqlite3.html] gives us ultimate control when importing data. We will first need to get the data into Python - we might choose to use the csv module for this. Next, we would use the Cursor.execute() [https://docs.python.org/3/library/sqlite3.html#sqlite3.Cursor.execute] method to create a table for our data.\n",
    "\n",
    "Lastly, we can use the Cursor.executemany() [https://docs.python.org/3/library/sqlite3.html#sqlite3.Cursor.executemany] method to insert multiple rows of data in a single command. If we create our connection object with a filename that doesn't exist, the sqlite module will create the database file for us.\n",
    "\n",
    "We should take advantage of the ? placeholder value syntax instead of using python string formatting to prevent SQL injection attacks (like the hilarious XKCD 'Bobby Tables' comic example) and maintain the correct data types. Even though in this project we won't be running any external user code, this is an extremely good habit to get into. Here's what our syntax would look like for the last step:\n",
    "\n",
    "my_list_of_lists = [\n",
    "    [4, 4, 8, 2],\n",
    "    [5, 1, 6, 3],\n",
    "    [5, 2, 4, 6]\n",
    "]\n",
    "c = \"\"\"\n",
    "INSERT INTO table_name (\n",
    "    column_one,\n",
    "    column_two,\n",
    "    [...]\n",
    ") VALUES (\n",
    "    ?,\n",
    "    ?\n",
    "    [...]\n",
    ");\n",
    "\"\"\"\n",
    "cur.executemany(c, my_list_of_lists)\n",
    "The advantage of this method is that we have the highest level of control over what we're doing. Additionally, if we have larger data, we can write a loop that iterates over our source line by line so that we don't have to read all of it into memory at once.\n",
    "\n",
    "The disadvantage is that there is a lot of manual data handling required.\n",
    "\n",
    "2. Using pandas\n",
    "\n",
    "The pandas library includes a handy DataFrame.to_sql() [https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_sql.html] method that we can use to send the contents of a dataframe to a SQLite connection object. We can either create the table first using the method above, or if the table does not exist, pandas will create it for us. Here's an example of what that looks like:\n",
    "\n",
    "my_dataframe.to_csv('table_name', sqlite_connection_object, index=False)\n",
    "Most of the time, we'll want to use index=False, otherwise pandas will create an extra column for the pandas index.\n",
    "\n",
    "The advantage of this method is that it can often be done with a line or two of code. The disadvantage is that pandas may alter the data as it reads it in and converts the columns to types automatically. Additionally, this requires the data to be small enough to be able to be stored in-memory using pandas.\n",
    "\n",
    "3. From the SQLite shell\n",
    "\n",
    "The last method is to use the SQLite shell to import the data. Like the pandas method, we can either create the table manually ourselves, or rely on SQLite to do it for us. Here's the commands you would use to import a CSV using the SQLite shell:\n",
    "\n",
    "sqlite> .mode csv\n",
    " sqlite> .import filename.csv table_name\n",
    "This is one of the quickest methods to use and works well with large data sources. There are several minor inconveniences to this method. SQLite detects the column types using the first row of data, which can lead to incorrect types. You'll need SQLite shell access, which you won't always have. Lastly, if you want to create the table yourself, you will need to remove the header from the first line of your CSV, otherwise SQLite will make that the first row of your table.\n",
    "\n",
    "With all of these methods, unless we explicitly create the table, the table will be created with no primary key. For now this isn't a problem as we'll be migrating this data into new, normalized tables.\n",
    "\n",
    "We'll use the pandas method in this instance, because we've already read the data into dataframes. The type conversion isn't a big issue– as outlined above we will move the data into new tables and can handle type conversion then.\n",
    "\n",
    "Hint: Just like in the previous guided project, our database retains 'state', so if we run a query that creates or modifies a table twice, the query will fail. Some commands like CREATE TABLE support IF NOT EXISTS which will allow you to run your notebook without these errors. You should consult the SQLite documentation [https://sqlite.org/lang.html] for the availability and syntax of these clauses.\n",
    "\n",
    "Instructions\n",
    "Recreate the run_command() and run_query() functions from the previous guided project, which you can use\n",
    "Use DataFrame.to_sql() to create tables for each of our dataframes in a new SQLite database, mlb.db:\n",
    "The table name should be the same as each of the CSV filename without the extension, eg game_log.csv should be imported to a table called game_log.\n",
    "Using run_command(), create a new column in the game_log table called game_id:\n",
    "Use SQL string concatenation to update the new columns with a unique ID using the Retrosheet format outlined above."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3. Looking for Normalization Opportunities\n",
    "\n",
    "When we spoke about database normalization in the previous mission, we mentioned that there were normal forms, a series of 5 progressive stages. Each of these stages have specific rules about the structure of the data that you can use to normalize.\n",
    "\n",
    "Rather than learn and follow specific normalized forms, we're going to look for specific opportunities to normalize our data by reducing repetition. Here are two examples of repetition we can find and remove:\n",
    "\n",
    "Repetition in columns\n",
    "\n",
    "Let's look at the following segment of data:\n",
    "\n",
    "v_player_1_id\tv_player_1_name\tv_player_1_def_pos\tv_player_2_id\tv_player_2_name\tv_player_2_def_pos\n",
    "villj001\tJonathan Villar\t5.0\tgenns001\tScooter Gennett\t4.0\n",
    "granc001\tCurtis Granderson\t8.0\tcabra002\tAsdrubal Cabrera\t6.0\n",
    "kendh001\tHowie Kendrick\t7.0\tturnj001\tJustin Turner\t5.0\n",
    "jasoj001\tJohn Jaso\t3.0\tpolag001\tGregory Polanco\t9.0\n",
    "gordd002\tDee Gordon\t4.0\ttelit001\tTomas Telis\t2.0\n",
    "\n",
    "We have three columns that relate to one player, followed by three columns that relate to another player. We could restructure our data to remove this repetition - we would need to add an extra column to include the data that was previously only contained in the name of the column:\n",
    "\n",
    "id\tname\tdef_pos\toff_pos\n",
    "villj001\tJonathan Villar\t5.0\t1.0\n",
    "granc001\tCurtis Granderson\t8.0\t1.0\n",
    "kendh001\tHowie Kendrick\t7.0\t1.0\n",
    "jasoj001\tJohn Jaso\t3.0\t1.0\n",
    "gordd002\tDee Gordon\t4.0\t1.0\n",
    "genns001\tScooter Gennett\t4.0\t2.0\n",
    "cabra002\tAsdrubal Cabrera\t6.0\t2.0\n",
    "turnj001\tJustin Turner\t5.0\t2.0\n",
    "polag001\tGregory Polanco\t9.0\t2.0\n",
    "telit001\tTomas Telis\t2.0\t2.0\n",
    "\n",
    "Non-primary key columns should be attributes of the primary key\n",
    "\n",
    "The primary key of our game log is our game_id, but the players name are not attributes of a game, but of the player id. If the only data we had was the game log, we would remove this column and create a new table that had the names of each player. As it happens, our person_codes table already has a list of our player IDs and names, so we can remove these without the need for creating a new table first.\n",
    "\n",
    "Redundant Data\n",
    "\n",
    "Lastly, we want to eliminate any redundant data - that is, columns where the data is available elsewhere. A good example of this can be found in our park_codes table, which will form the basis of our eventual park table. Let's look at the first few rows (we won't display the notes column as is not relevant to our discussion):\n",
    "\n",
    "park_id\tname\taka\tcity\tstate\tstart\tend\tleague\n",
    "ALB01\tRiverside Park\tNaN\tAlbany\tNY\t09/11/1880\t05/30/1882\tNL\n",
    "ALT01\tColumbia Park\tNaN\tAltoona\tPA\t04/30/1884\t05/31/1884\tUA\n",
    "ANA01\tAngel Stadium of Anaheim\tEdison Field; Anaheim Stadium\tAnaheim\tCA\t04/19/1966\tNaN\tAL\n",
    "ARL01\tArlington Stadium\tNaN\tArlington\tTX\t04/21/1972\t10/03/1993\tAL\n",
    "ARL02\tRangers Ballpark in Arlington\tThe Ballpark in Arlington; Ameriquest Fl\tArlington\tTX\t04/11/1994\tNaN\tAL\n",
    "\n",
    "The start and end columns show the first and last games played at the park, however we will be able to derive this information by looking at the park information for each game. Similarly, the league information is going to be available elsewhere in our database.\n",
    "\n",
    "Instructions\n",
    "Looking at the various files, look for opportunities to normalize the data and record your observations in a markdown cell."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4. Planning a Normalized Schema\n",
    "\n",
    "Now that we've started to think about normalization ideas, it's time to start planning our schema. The best way to work visually with a schema diagram, just like the ones we've used so far in this course. Start by creating a diagram of the four existing tables and their columns, and then gradually create new tables that move the data into a more normalized state.\n",
    "\n",
    "Some people like to do this on paper, others use diagramming tools like Sketch or Figma, others like using Photoshop or similar. Our recommendation is that the best way to do this is using a schema designing tool like DbDesigner.net. This free tool allows you to create a schema and will create lines to show foreign key relations clearly.\n",
    "\n",
    "DbDesigner.net\n",
    "\n",
    "In the end, you should choose the tool that you feel like you will be able to work quickly in as you plan out your schema.\n",
    "\n",
    "Here are some tips when planning out your schema:\n",
    "\n",
    "Don't be afraid to experiment. It's unlikely that your first few steps will be there in your finished product - try things and see how they look.\n",
    "If you're using a tool like DbDesigner [https://dbdesigner.net/] which automatically shows lines for foreign key relationships, don't worry if your lines look messy. This is normal– you can move the tables around to neaten things up at the end, but don't waste time on it while you are still normalizing.\n",
    "The following facts about the data may help you with your normalization decisions:\n",
    "Historically, teams sometimes move between leagues.\n",
    "The same person might be in a single game as both a player and a manager\n",
    "Because of how pitchers are represented in the game log, not all pitchers used in a game will be shown. We only want to worry about the pitchers mentioned via position or the 'winning pitcher'/ 'losing pitcher'.\n",
    "It is possible to over-normalize. We want to finish with about 7-8 tables total.\n",
    "Lastly, we advise spending between 60-90 minutes on your planning your schema. In the next step, we will introduce our suggested schema that we will work with for the rest of the project, but working as much of it out yourself is highly recommended.\n",
    "\n",
    "Instructions\n",
    "Using whichever design tool you feel most comfortable with, plan a schema for our baseball database.\n",
    "When you are happy with your schema, insert a screenshot or photo into a markdown cell. [https://daringfireball.net/projects/markdown/syntax#img]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "5. Creating Tables Without Foreign Key Relations\n",
    "\n",
    "So that we can work through the rest of the steps together, we will provide a schema for the rest of this guided project. As we work through each table, we'll explain some of the decision made when normalizing and creating the schema. Below is the schema we will use:\n",
    "\n",
    "MLB Schema\n",
    "https://s3.amazonaws.com/dq-content/193/mlb_schema.svg\n",
    "\n",
    "As we work through creating the tables in this schema, we'll talk about why we made particular choices during the normalization process. We'll start by creating the tables that don't contain any foreign key relations. It's important to start with these tables, as other tables will have relations to these tables, and so these tables will need to exist first.\n",
    "\n",
    "The tables we will create are below, with some notes on the normalization choices made:\n",
    "\n",
    "person\n",
    "Each of the 'debut' columns have been omitted, as the data will be able to be found from other tables.\n",
    "Since the game log file has no data on coaches, we made the decision to not include this data.\n",
    "park\n",
    "The start, end, and league columns contain data that is found in the main game log and can be removed.\n",
    "league\n",
    "Because some of the older leagues are not well known, we will create a table to store league names.\n",
    "appearance_type\n",
    "Our appearance table will include data on players with positions, umpires, managers, and awards (like winning pitcher). This table will store information on what different types of appearances are available.\n",
    "We'll first create each table, and then we'll insert the data. Previously, we learned to use the CREATE statement with the VALUES clause to manually specify values to be inserted. For the person and park tables, we have person_codes and park_codes which contain the data we'll need. To use this data we'll CREATE with SELECT:\n",
    "\n",
    "INSERT INTO table_one\n",
    "SELECT * FROM table_two;\n",
    "Note that you will need to adjust the select statement to specify select columns in order, since our original table and new table have different number of columns in different orders.\n",
    "\n",
    "Similar to IF NOT EXISTS, we can use INSERT OR IGNORE [https://www.sqlite.org/lang_insert.html] as specified in the SQLite documentation to prevent our code from failing if we run it a second time in our notebook.\n",
    "\n",
    "For the league table you will need to manually specify the values, and for appearance_type we have provided a appearance_type.csv that you can import which contains all the values you need for this table.\n",
    "\n",
    "Instructions\n",
    "Create the person table with columns and primary key as shown in the schema diagram.\n",
    "Select the appropriate type based on the data.\n",
    "Insert the data from the person_codes table.\n",
    "Write a query to display the first few rows of the table.\n",
    "Create the park table with columns and primary key as shown in the schema diagram.\n",
    "Select the appropriate type based on the data\n",
    "Insert the data from the park_codes table.\n",
    "Write a query to display the first few rows of the table.\n",
    "Create the league table with columns and primary key as shown in the schema diagram.\n",
    "Select the appropriate type based on the data.\n",
    "Insert the data manually based on your research on the names of the six league IDs.\n",
    "Write a query to display the table.\n",
    "Create the appearance_type table with columns and primary key as shown in the schema diagram.\n",
    "Select the appropriate type based on the data.\n",
    "Import and insert the data from appearance_type.csv.\n",
    "Write a query to display the table."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "6. Adding The Team and Game Tables\n",
    "\n",
    "Now that we have added all of the tables that don't have foreign key relationships, lets add the next two tables. The game and team tables need to exist before our two appearance tables are created. Here are the schema of these tables, and the two tables they have foreign key relations to:\n",
    "\n",
    "MLB Schema for game and team\n",
    "https://s3.amazonaws.com/dq-content/193/mlb_schema_2.svg\n",
    "\n",
    "Here are some notes on the normalization choices made with each of these tables:\n",
    "\n",
    "team\n",
    "The start, end, and sequence columns can be derived from the game level data.\n",
    "game\n",
    "We have chosen to include all columns for the game log that don't refer to one specific team or player, instead putting those in two appearance tables.\n",
    "We have removed the column with the day of the week, as this can be derived from the date.\n",
    "We have changed the day_night column to day, with the intention of making this a boolean column. Even though SQLite doesn't support the BOOLEAN type, we can use this when creating our table and SQLite will manage the underlying types behind the scenes (for more on how this works refer to the SQLite documentation. This means that anyone quering the schema of our database in the future understands how that column is intended to be used.\n",
    "In an earlier mission, we discussed in passing that by default, SQLite doesn't enforce foreign key relationships. To ensure the integrity of our data, we need to make sure we enable it after each time we create a sqlite3 connection object in python.\n",
    "\n",
    "If you are re-using the run_command() function from the earlier guided project, you can add a single line to enable enforcement of foreign key restraints:\n",
    "\n",
    "def run_command(c):\n",
    "    with sqlite3.connect(DB) as conn:\n",
    "        conn.execute('PRAGMA foreign_keys = ON;')\n",
    "        conn.isolation_level = None\n",
    "        conn.execute(c)\n",
    "Let's create the team and game tables.\n",
    "\n",
    "Instructions\n",
    "Create the team table with columns, primary key, and foreign key as shown in the schema diagram.\n",
    "Select the appropriate type based on the data.\n",
    "Insert the data from the team_codes table.\n",
    "Write a query to display the first few rows of the table.\n",
    "Create the game table with columns, primary key, and foreign key as shown in the schema diagram.\n",
    "Select the appropriate type based on the data.\n",
    "Insert the data from the game_log table.\n",
    "Write a query to display the first few rows of the table."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "7. Adding the Team Appearance Table\n",
    "\n",
    "At this point, because we have told SQLite to enforce foreign key constraints and have inserted data that obeys these contraints, we'll get an error if we try to drop a table or delete rows within a table. For example, you might try running DELETE FROM park where park_id = \"FOR01\";. If you get stuck, one option is to run !rm mlb.db in its own Jupyter cell to delete the database file so you can run all your cells to recreate the database files, tables and data.\n",
    "\n",
    "Our next task is to add the team_appearance table. Here is the schema of the table and the three tables it has foreign key relations to:\n",
    "\n",
    "MLB Schema for team_appearance\n",
    "https://s3.amazonaws.com/dq-content/193/mlb_schema_3.svg\n",
    "\n",
    "The team_appearance table has a compound primary key composed of the team name and the game ID. In addition, a boolean column home is used to differentiate between the home and the away team. The rest of the columns are scores or statistics that in our original game log are repeated for each of the home and away teams.\n",
    "\n",
    "In order to insert this data cleanly, we'll need to use a UNION clause:\n",
    "\n",
    "INSERT INTO team_appearance\n",
    "    SELECT\n",
    "        h_name,\n",
    "        game_id,\n",
    "        1 AS home,\n",
    "        h_league,\n",
    "        h_score,\n",
    "        h_line_score,\n",
    "        h_at_bats,\n",
    "        [...]\n",
    "    FROM game_log\n",
    "​\n",
    "UNION\n",
    "​\n",
    "    SELECT    \n",
    "        v_name,\n",
    "        game_id,\n",
    "        0 AS home,\n",
    "        v_league,\n",
    "        v_score,\n",
    "        v_line_score,\n",
    "        v_at_bats,\n",
    "        [...]\n",
    "    from game_log;\n",
    "In order to save yourself from having to manually type all the column names, you might like to use a query like the following to extract the schema from the game_log table, and use that as a starting point for your query:\n",
    "\n",
    "SELECT sql FROM sqlite_master\n",
    "WHERE name = \"game_log\"\n",
    "  AND type = \"table\";\n",
    "\n",
    "Instructions\n",
    "Create the person_appearance table with columns, primary key, and foreign keys as shown in the schema diagram.\n",
    "Select the appropriate type based on the data.\n",
    "Insert the data from the game_log table, using UNION clauses to combine the data from the columns for managers, umpires, pitchers, and awards.\n",
    "Use a loop with string formatting to insert the data for offensive and defensive positions from the game_log table.\n",
    "Write a query to verify that your data was inserted correctly."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "8. Adding the Person Appearance Table\n",
    "\n",
    "The final table we need to create is person_appearance. Here is the schema of the table and the four tables it has foreign key relations to:\n",
    "\n",
    "MLB Schema for team_appearance\n",
    "https://s3.amazonaws.com/dq-content/193/mlb_schema_4.svg\n",
    "\n",
    "The person_appearance table will be used to store information on appearances in games by managers, players, and umpires as detailed in the appearance_type table.\n",
    "\n",
    "We'll need to use a similar technique to insert data as we used with the team_appearance table, however we will have to write much larger queries - one for each column instead of one for each team as before. We will need to work out for each column what the appearance_type_id will be by cross-referencing the columns with the appearance_type table.\n",
    "\n",
    "We have decided to create an integer primary key for this table, because having every column be a compound primary quickly becomes cumbersome when writing queries. In SQLite, if you have an integer primary key and don't specify a value for this column when inserting rows, SQLite will autoincrement this column for you.\n",
    "\n",
    "Below is an excerpt of the query that we'll write to insert the data:\n",
    "\n",
    "INSERT INTO person_appearance (\n",
    "    game_id,\n",
    "    team_id,\n",
    "    person_id,\n",
    "    appearance_type_id\n",
    ")\n",
    "    SELECT\n",
    "        game_id,\n",
    "        NULL,\n",
    "        lf_umpire_id,\n",
    "        \"ULF\"\n",
    "    FROM game_log\n",
    "    WHERE lf_umpire_id IS NOT NULL\n",
    "​\n",
    "UNION\n",
    "​\n",
    "    SELECT\n",
    "        game_id,\n",
    "        NULL,\n",
    "        rf_umpire_id,\n",
    "        \"URF\"\n",
    "    FROM game_log\n",
    "    WHERE rf_umpire_id IS NOT NULL\n",
    "​\n",
    "UNION\n",
    "​\n",
    "    SELECT\n",
    "        game_id,\n",
    "        v_name,\n",
    "        v_manager_id,\n",
    "        \"MM\"\n",
    "    FROM game_log\n",
    "    WHERE v_manager_id IS NOT NULL\n",
    "​\n",
    "UNION\n",
    "​\n",
    "    SELECT\n",
    "        game_id,\n",
    "        h_name,\n",
    "        h_manager_id,\n",
    "        \"MM\"\n",
    "    FROM game_log\n",
    "    WHERE h_manager_id IS NOT NULL\n",
    "​\n",
    "UNION\n",
    "​\n",
    "    SELECT\n",
    "        game_id,\n",
    "        CASE\n",
    "            WHEN h_score > v_score THEN h_name\n",
    "            ELSE v_name\n",
    "            END,\n",
    "        winning_pitcher_id,\n",
    "        \"AWP\"\n",
    "    FROM game_log\n",
    "    WHERE winning_pitcher_id IS NOT NULL\n",
    "​\n",
    "UNION\n",
    "    [...]\n",
    "When we get to the offensive and defensive positions for both teams, we essentially are performing 36 permutations: 2 (home, away) * 2 (offense + defense) * 9 (9 positions).\n",
    "\n",
    "To save us from manually copying this out, we can instead use a loop and python string formatting [https://pyformat.info/] to generate the queries:\n",
    "\n",
    "template = \"\"\"\n",
    "INSERT INTO person_appearance (\n",
    "    game_id,\n",
    "    team_id,\n",
    "    person_id,\n",
    "    appearance_type_id\n",
    ") \n",
    "    SELECT\n",
    "        game_id,\n",
    "        {hv}_name,\n",
    "        {hv}_player_{num}_id,\n",
    "        \"O{num}\"\n",
    "    FROM game_log\n",
    "    WHERE {hv}_player_{num}_id IS NOT NULL\n",
    "​\n",
    "UNION\n",
    "​\n",
    "    SELECT\n",
    "        game_id,\n",
    "        {hv}_name,\n",
    "        {hv}_player_{num}_id,\n",
    "        \"D\" || CAST({hv}_player_{num}_def_pos AS INT)\n",
    "    FROM game_log\n",
    "    WHERE {hv}_player_{num}_id IS NOT NULL;\n",
    "\"\"\"\n",
    "​\n",
    "run_command(c1)\n",
    "run_command(c2)\n",
    "​\n",
    "for hv in [\"h\",\"v\"]:\n",
    "    for num in range(1,10):\n",
    "        query_vars = {\n",
    "            \"hv\": hv,\n",
    "            \"num\": num\n",
    "        }\n",
    "        # run commmand is a helper function which runs\n",
    "        # a query against our database.\n",
    "        run_command(template.format(**query_vars))\n",
    "        \n",
    "Instructions\n",
    "Launch the SQLite shell, connected to the chinook.db database.\n",
    "Add two new columns, with values, to the invoice table:\n",
    "tax, with type NUMERIC.\n",
    "The value for all existing rows should be 0.\n",
    "subtotal, with type NUMERIC.\n",
    "The value for each row should be the same as that row's value for total.\n",
    "Quit the SQLite shell."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "9. Removing the Original Tables\n",
    "\n",
    "We've now created all normalized tables and inserted all of our data!\n",
    "\n",
    "Our last task is to remove the tables we created to import the original CSVs.\n",
    "\n",
    "Instructions\n",
    "Drop the tables we created to hold our unnormalized data:\n",
    "game_log.\n",
    "park_codes.\n",
    "team_codes.\n",
    "person_codes."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "10. Next Steps\n",
    "\n",
    "In this mission, we learned how to:\n",
    "\n",
    "Import CSV data into a database.\n",
    "Design a normalized schema for a large, predominantly single table data set.\n",
    "Create tables that match the schema design.\n",
    "Migrate data from unnormalized tables into our normalized tables.\n",
    "To extend this project, you might like to consider one or more of the following:\n",
    "\n",
    "Transform the the dates into a SQLite compatible format. [https://www.sqlite.org/lang_datefunc.html]\n",
    "Extract the line scores into innings level data in a new table.\n",
    "Create views to make querying stats easier, eg:\n",
    "Season level stats.\n",
    "All time records.\n",
    "Supplement the database using new data, for instance:\n",
    "Add data from retrosheet game logs for years after 2016.\n",
    "Source and add missing pitcher information.\n",
    "Add player level per-game stats.\n",
    "Source and include base coach data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
