{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 Data Analysis and Visualisation - Working with Missing Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Introduction\n",
    "\n",
    "In this mission, we'll clean and analyze data on passenger survival from the Titanic. Each row contains information for a specific Titanic passenger.\n",
    "\n",
    "Here are the first few rows of the dataset:\n",
    "\n",
    "Lets take a closer look at a few of the key columns:\n",
    "\n",
    "pclass -- The passenger's cabin class from 1 to 3 where 1 was the highest class\n",
    "survived -- 1 if the passenger survived, and 0 if they did not.\n",
    "sex -- The passenger's gender\n",
    "age -- The passenger's age\n",
    "fare -- The amount the passenger paid for their ticket\n",
    "embarked -- Either C, Q, or S, to indicate which port the passenger boarded the ship from.\n",
    "Many of the columns, such as age and sex, have missing values.\n",
    "\n",
    "Because missing values can cause errors in numerical functions, we'll need to deal with them before we can analyze the data. For instance, finding the mean of a column with a missing value will fail because it's impossible to average a missing value. Addressing missing values will let us perform calculations on the entire data set."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2. Introduction\n",
    "\n",
    "Let's import the data set into pandas. You may notice at the start of the code, we import pandas differently from how we have previously.\n",
    "\n",
    "import pandas as pd\n",
    "This gives the pandas library the alias pd, so that instead of typing pandas every time we want to use a function, we can instead type pd, for example pd.read_csv().\n",
    "\n",
    "Instructions\n",
    "Read the file titanic_survival.csv into a dataframe called titanic_survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "titanic_survival = pd.read_csv('titanic_survival.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3. Finding the Missing Data\n",
    "\n",
    "Missing data can take a few different forms:\n",
    "\n",
    "In Python, the None keyword and type indicates no value.\n",
    "The Pandas library uses NaN, which stands for \"not a number\", to indicate a missing value.\n",
    "In general terms, both NaN and None can be called null values.\n",
    "\n",
    "If we want to see which values are NaN, we can use the pandas.isnull() function which takes a pandas series and returns a series of True and False values, the same way that NumPy did when we compared arrays.\n",
    "\n",
    "sex = titanic_survival[\"sex\"]\n",
    "sex_is_null = pandas.isnull(sex)\n",
    "We can use this resultant series to select only the rows that have null values.\n",
    "\n",
    "sex_null_true = sex[sex_is_null]\n",
    "We'll use this structure to look at the null values for the \"age\" column.\n",
    "\n",
    "Instructions\n",
    "Count how many values in the \"age\" column have null values:\n",
    "Use pandas.isnull() on age variable to create a Series of True and False values.\n",
    "Use the resulting series to select only the elements in age that are null, and assign the result to age_null_true\n",
    "Assign the length of age_null_true to age_null_count.\n",
    "Print age_null_count to see how many null values are in the \"age\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age = titanic_survival[\"age\"]\n",
    "print(age.loc[10:20])\n",
    "\n",
    "age_is_null = pd.isnull(age)\n",
    "age_null_true = age[age_is_null]\n",
    "age_null_count = len(age_null_true)\n",
    "\n",
    "print(age_null_count)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4. What's the big deal with missing data?\n",
    "\n",
    "So, we know that quite a few values are missing from the \"age\" column, and other columns are missing data too. But why is this a problem?\n",
    "\n",
    "Lets look at a typical approach to calculate the average for the \"age\" column:\n",
    "\n",
    "mean_age = sum(titanic_survival[\"age\"]) / len(titanic_survival[\"age\"])\n",
    "The result of this is that mean_age would be nan. This is because any calculations we do with a null value also result in a null value. This makes sense when you think about it -- how can you add a null value to a known value?\n",
    "\n",
    "Instead, we have to filter out the missing values before we calculate the mean.\n",
    "\n",
    "Instructions\n",
    "Use age_is_null to create a vector that only contains values from the \"age\" column that aren't NaN.\n",
    "Calculate the mean of the new vector, and assign the result to correct_mean_age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age_is_null = pd.isnull(titanic_survival[\"age\"])\n",
    "\n",
    "age = titanic_survival[\"age\"]\n",
    "age_not_null = age[age_is_null == False]\n",
    "\n",
    "correct_mean_age = age_not_null.mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "5. Easier Ways to Do Math\n",
    "\n",
    "Luckily, missing data is so common that many pandas methods automatically filter for it. For example, if we use use the Series.mean() method to calculate the mean of a column, missing values will not be included in the calculation.\n",
    "\n",
    "To calculate the mean age that we did earlier, we can replace all of our code with one line\n",
    "\n",
    "correct_mean_age = titanic_survival[\"age\"].mean()\n",
    "Using the built in method is much easier, but it's important to understand what is happening behind the scenes.\n",
    "\n",
    "Instructions\n",
    "Assign the mean of the \"fare\" column to correct_mean_fare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_mean_age = titanic_survival[\"age\"].mean()\n",
    "\n",
    "correct_mean_fare = titanic_survival['fare'].mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "6. Calculating Summary Statistics\n",
    "\n",
    "Let's calculate more summary statistics for the data. The pclass column indicates the cabin class for each passenger, which was either first class (1), second class (2), or third class (3). You'll use the list passenger_classes, which contains these values, in the following exercise.\n",
    "\n",
    "Instructions\n",
    "Use a for loop to iterate over passenger_classes. Within the for loop:\n",
    "Select just the rows in titanic_survival where the pclass value is equivalent to the current iterator value (class).\n",
    "Select just the fare column for the current subset of rows.\n",
    "Use the Series.mean method to calculate the mean of this subset.\n",
    "Add the mean of the class to the fares_by_class dictionary with class as the key.\n",
    "Once the loop completes, the dictionary fares_by_class should have 1, 2, and 3 as keys, with the average fares as the corresponding values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "passenger_classes = [1, 2, 3]\n",
    "fares_by_class = {}\n",
    "\n",
    "for index in passenger_classes:\n",
    "    is_class = titanic_survival['pclass'] == index\n",
    "    fare = titanic_survival['fare']\n",
    "    mean_fare = fare[is_class].mean()\n",
    "    fares_by_class[index] = mean_fare"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "7. Making Pivot Tables\n",
    "\n",
    "Pivot tables [http://pandas.pydata.org/pandas-docs/stable/generated/pandas.pivot_table.html] provide an easy way to subset by one column and then apply a calculation like a sum or a mean. The concept of Pivot tables was popularized with the introduction of the 'PivotTable' feature in Microsoft Excel in the mid 1990's.\n",
    "\n",
    "Pivot tables first group and then apply a calculation. In the previous screen, we actually made a pivot table manually by grouping by the column \"pclass\" and then calculating the mean of the \"fare\" column for each class.\n",
    "\n",
    "Luckily, we can use the Dataframe.pivot_table() method instead, which simplifies the kind of work we did on the last screen. To produce the same data, we could use one line.\n",
    "\n",
    "passenger_class_fares = titanic_survival.pivot_table(index=\"pclass\", values=\"fare\", aggfunc=np.mean)\n",
    "The first parameter of the method, index tells the method which column to group by. The second parameter values is the column that we want to apply the calculation to, and aggfunc specifies the calculation we want to perform. The default for the aggfunc parameter is actually the mean, so if we're calculating this we can omit this parameter.\n",
    "\n",
    "Instructions\n",
    "Use the DataFrame.pivot_table() method to calculate the mean age for each passenger class (\"pclass\").\n",
    "Assign the result to passenger_age.\n",
    "Display the passenger_age pivot table using the print() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "passenger_survival = titanic_survival.pivot_table(index=\"pclass\", values=\"survived\")\n",
    "\n",
    "passenger_age = titanic_survival.pivot_table(index='pclass', values='age')\n",
    "print(passenger_age)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "8. More Complex Pivot Tables\n",
    "\n",
    "We can use the DataFrame.pivot_table() method to perform even more advanced tasks. If we pass a list of column names to the values parameter instead of a single value, we can perform calculations on multiple columns at once.\n",
    "\n",
    "We can also specify a custom calculation to be made. For instance, if we pass np.sum to the aggfunc parameter it will total the values in each column.\n",
    "\n",
    "Instructions\n",
    "Make a pivot table that calculates the total fares collected (\"fare\") and total number of survivors (\"survived\") for each embarkation port (\"embarked\").\n",
    "Assign the result to port_stats.\n",
    "Display port_stats using the print() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "port_stats = titanic_survival.pivot_table(index='embarked', values=['fare','survived'], aggfunc=np.sum)\n",
    "#port_stats = titanic_survival.pivot_table(index='pclass', values=['sibsp','survived'], aggfunc=np.mean)\n",
    "\n",
    "print(port_stats)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "9. Drop Missing Values\n",
    "\n",
    "We learned how to remove the missing values in a vector of data, but how about in a matrix?\n",
    "\n",
    "We can use the DataFrame.dropna() method on pandas DataFrames to do this. The method will drop any rows that contain missing values.\n",
    "\n",
    "The dropna() method takes an axis parameter, which indicates whether you would like to drop rows or columns. Specifying axis=0 or axis='index' will drop any rows that have null values, while specifying axis=1 or axis='columns' will drop any columns that have null values. We will use 0 and 1 since they're more commonly used, but you can use either.\n",
    "\n",
    "The code below will drop all rows in titanic_survival that have null values.\n",
    "\n",
    "drop_na_rows = titanic_survival.dropna(axis=0)\n",
    "There is also a parameter that allows you to specify a list of columns or rows to look at when using dropna(). You will need to use this in the next exercise - take a look at the documentation [http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.dropna.html] to work out the name of this parameter and how it works.\n",
    "\n",
    "Instructions\n",
    "Drop all columns in titanic_survival that have missing values and assign the result to drop_na_columns.\n",
    "Drop all rows in titanic_survival where the columns \"age\" or \"sex\" have missing values and assign the result to new_titanic_survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_na_rows = titanic_survival.dropna(axis=0)\n",
    "\n",
    "down_na_columns = titanic_survival.dropna(axis=1)\n",
    "new_titanic_survival = titanic_survival.dropna(axis=0, subset=['age','sex'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "10. Using iloc to Access Rows by Position\n",
    "\n",
    "In previous missions, we have used row labels to select data in pandas using Dataframe.loc[]. These work just like column labels, and can be values like numbers, characters, and strings.\n",
    "\n",
    "Sometimes your dataset will have row labels that are not numbers, or that are not in order. We have sorted the new_titanic_survival dataframe by the \"age\" column from highest to lowest. Here is a preview of the a few of the columns for the first five rows of the data, or the five oldest passengers onboard.\n",
    "\n",
    "pclass\tsurvived\tname\tsex\tage\n",
    "14\t1.0\t1.0\tBarkworth, Mr. Algernon Henry Wilson\tmale\t80.0\n",
    "61\t1.0\t1.0\tCavendish, Mrs. Tyrell William (Julia Florence...\tfemale\t76.0\n",
    "1235\t3.0\t0.0\tSvensson, Mr. Johan\tmale\t74.0\n",
    "135\t1.0\t0.0\tGoldschmidt, Mr. George B\tmale\t71.0\n",
    "9\t1.0\t0.0\tArtagaveytia, Mr. Ramon\tmale\t71.0\n",
    "You can see that the row labels for the first 5 rows are 14, 61, 1235, 135 and 9. If we wanted to select the first five rows, we can use DataFrame.iloc[] method to select by position. The easy way to remember which is which is to remember that iloc[] stands for integer location, because you use integers and not labels to select the data.\n",
    "\n",
    "The following code will select the first 5 rows as shown above:\n",
    "\n",
    "first_five_rows = new_titanic_survival.iloc[0:5]\n",
    "\n",
    "Instructions\n",
    "Assign the first ten rows from new_titanic_survival to first_ten_rows.\n",
    "Assign the fifth row from new_titanic_survival to row_position_fifth.\n",
    "Assign the row with index label 25 from new_titanic_survivalto row_index_25.                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We have already sorted new_titanic_survival by age\n",
    "first_five_rows = new_titanic_survival.iloc[0:5]\n",
    "\n",
    "first_ten_rows = new_titanic_survival.iloc[0:10]\n",
    "row_position_fifth = new_titanic_survival.iloc[4]\n",
    "row_index_25 = new_titanic_survival.loc[25]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "11. Using Column Indexes\n",
    "We can also index columns using both the loc[] and iloc[] methods. With .loc[], we specify the column label strings as we have in the earlier exercises in this missions. With iloc[], we simply use the integer number of the column, starting from the left-most column which is 0. Similar to indexing with NumPy arrays, you separate the row and columns with a comma, and can use a colon to specify a range or as a wildcard.\n",
    "\n",
    "first_row_first_column = new_titanic_survival.iloc[0,0]\n",
    "all_rows_first_three_columns = new_titanic_survival.iloc[:,0:3]\n",
    "row_index_83_age = new_titanic_survival.loc[83,\"age\"]\n",
    "row_index_766_pclass = new_titanic_survival.loc[766,\"pclass\"]\n",
    "\n",
    "Instructions\n",
    "Assign the value at row index label 1100, column index label \"age\" from new_titanic_survival to row_index_1100_age.\n",
    "Assign the value at row index label 25, column index label \"survived\" from new_titanic_survival to row_index_25_survived.\n",
    "Assign the first 5 rows and first three columns from new_titanic_survival to five_rows_three_cols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_row_first_column = new_titanic_survival.iloc[0,0]\n",
    "all_rows_first_three_columns = new_titanic_survival.iloc[:,0:3]\n",
    "row_index_83_age = new_titanic_survival.loc[83,\"age\"]\n",
    "row_index_766_pclass = new_titanic_survival.loc[766,\"pclass\"]\n",
    "\n",
    "row_index_1100_age = new_titanic_survival.loc[1100, 'age']\n",
    "row_index_25_survived = new_titanic_survival.loc[25, 'survived']\n",
    "five_rows_three_cols = new_titanic_survival.iloc[0:5,0:3]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "12. Reindexing Rows\n",
    "\n",
    "After we sorted new_titanic_survival by age, the row indexes were no longer sequential. Each row retained its original index from titanic_survival.\n",
    "\n",
    "Sometimes it's useful to reindex, starting from 0. We can use the DataFrame.reset_index() method to do this. By default, the method retains the old index by adding an extra column to the dataframe with the old index values.\n",
    "\n",
    "In this exercise, we don't want to retain the index. Check the documentation to see what parameter you need to add so that we don't retain the old index.\n",
    "\n",
    "Instructions\n",
    "Reindex the new_titanic_survival dataframe so the row indexes start from 0, and the old index is dropped.\n",
    "Assign the final result to titanic_reindexed.\n",
    "Print the first 5 rows and the first 3 columns of titanic_reindexed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_reindexed = new_titanic_survival.reset_index(drop=True)\n",
    "print(titanic_reindexed.iloc[0:5,0:3])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "13. Apply Functions Over a DataFrame\n",
    "\n",
    "To perform a complex calculation across pandas objects, we'll need to learn about the DataFrame.apply() method. By default, DataFrame.apply() will iterate through each column in a DataFrame, and perform on each column. When we create our function, we give it one parameter, apply() method passes each column to the parameter as a pandas series.\n",
    "\n",
    "The result from the function will be combined with all of the other results, and placed into a new series. The function results will have the same position as the column or row we generated them from. Let's look at a simple example:\n",
    "\n",
    "# This function returns the hundredth item from a series\n",
    "def hundredth_row(column):\n",
    "    # Extract the hundredth item\n",
    "    hundredth_item = column.iloc[99]\n",
    "    return hundredth_item\n",
    "​\n",
    "# Return the hundredth item from each column\n",
    "hundredth_row_var = titanic_survival.apply(hundredth_row)\n",
    "\n",
    "Instructions\n",
    "Write a function that counts the number of null elements in a Series.\n",
    "Use the DataFrame.apply() method along with your function to run across all the columns in titanic_survival.\n",
    "Assign the result to column_null_count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hundredth_row(column):\n",
    "    hundredth_item = column.iloc[99]\n",
    "    return hundredth_item\n",
    "\n",
    "hundredth_row_var = titanic_survival.apply(hundredth_row)\n",
    "\n",
    "def count_null(column):\n",
    "    is_null = column.isnull()\n",
    "    null_list = column[is_null]\n",
    "    return len(null_list)\n",
    "\n",
    "column_null_count = titanic_survival.apply(count_null)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "14. Applying a Function to a Row\n",
    "\n",
    "By passing in the axis=1 argument, we can use the DataFrame.apply() method to iterate over rows instead of columns.\n",
    "\n",
    "We can use this to calculate some summary information about the ages of the passengers on the Titanic. You will need to use an if/elif/else statement in your function. The elif statement just means else if. Below is an example of how these statements work.\n",
    "\n",
    "def which_class(row):\n",
    "    pclass = row['pclass']\n",
    "    if pd.isnull(pclass):\n",
    "        return \"Unknown\"\n",
    "    elif pclass == 1:\n",
    "        return \"First Class\"\n",
    "    elif pclass == 2:\n",
    "        return \"Second Class\"\n",
    "    else:\n",
    "        return \"Third Class\"\n",
    "​\n",
    "classes = titanic_survivors.apply(which_class, axis=1)\n",
    "When the function is called, each test runs until one of the if, elif or else statements is met.\n",
    "\n",
    "Instructions\n",
    "Create a function that returns the string \"minor\" if someone is under 18, \"adult\" if they are equal to or over 18, and \"unknown\" if their age is null.\n",
    "Then, use the function along with .apply() to find the correct label for everyone in the titanic_survival dataframe.\n",
    "Assign the result to age_labels.\n",
    "You can use pd.isnull to check if a value is null or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_minor(row):\n",
    "    if row[\"age\"] < 18:\n",
    "        return \"minor\"\n",
    "    elif row['age'] >= 18:\n",
    "        return \"adult\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "age_labels = titanic_survival.apply(is_minor, axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "15. Calculating Survival Percentage by Age Group\n",
    "\n",
    "Now that we have age labels for everyone, let's make a pivot table to find the probability of survival for each age group.\n",
    "\n",
    "We have added an \"age_labels\" column to the dataframe containing the age_labels variable from the previous step.\n",
    "\n",
    "Instructions\n",
    "Create a pivot table that calculates the mean survival chance(\"survived\") for each age group (\"age_labels\") of the dataframe titanic_survival.\n",
    "Assign the resulting Series object to age_group_survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age_group_survival = titanic_survival.pivot_table(index='age_labels', values='survived')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
