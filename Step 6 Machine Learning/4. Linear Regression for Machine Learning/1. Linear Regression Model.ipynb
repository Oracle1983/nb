{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 Machine Learning -  Linear Regression Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Instance Based Learning Vs. Model Based Learning\n",
    "\n",
    "In the first course in this step, Machine Learning Fundamentals, we walked through the full machine learning workflow using the k-nearest neighbors algorithm. K-nearest neighbors works by finding similar, labelled examples from the training set for each instance in the test set and uses them to predict the label. K-nearest neighbors is known as an instance-based learning algorithm because it relies completely on previous instances to make predictions. The k-nearest neighbors algorithm doesn't try to understand or capture the relationship between the feature columns and the target column.\n",
    "\n",
    "Because the entire training dataset is used to find a new instance's nearest neighbors to make label predictions, this algorithm doesn't scale well to medium and larger datasets. If we have a million instances in our training data set and we want to make predictions for a hundred thousand new instances, we'd have to sort the million instances in the training set by Euclidean distance for each instance. The following diagram provides an overview of the complexity of k-nearest neighbors:\n",
    "\n",
    "KNN Complexity\n",
    "https://s3.amazonaws.com/dq-content/235/knn_complexity.svg\n",
    "\n",
    "We need to instead learn about parametric machine learning approaches, like linear regression and logistic regression. Unlike the k-nearest neighbors algorithm, the result of the training process for these machine learning algorithms is a mathematical function that best approximates the patterns in the training set. In machine learning, this function is often referred to as a model.\n",
    "\n",
    "In this course, we'll explore the most commonly used machine learning model -- the linear regression model. Parametric machine learning approaches work by making assumptions about the relationship between the features and the target column. In linear regression, the approximate relationship between the feature columns and the target column is expressed as a linear regression equation:\n",
    "\n",
    "\n",
    "The following diagram provides an overview of the machine learning process for linear regression. For now, the goal isn't to understand the entire process but more to compare and contrast with the nonparametric approach of k-nearest neighbors.\n",
    "\n",
    "Model Based Learning\n",
    "https://s3.amazonaws.com/dq-content/235/regression_complexity.svg\n",
    "\n",
    "In this mission, we'll provide an overview of how we use a linear regression model to make predictions. We'll use scikit-learn for the model training process, so we can focus on gaining intuition for the model-based learning approach to machine learning. In later missions in this course, we'll dive the math behind how a model is fit to the dataset, how to select and transform features, and more.\n",
    "\n",
    "In the next screen, we'll introduce the dataset we'll be using throughout this course."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2. Introduction To The Data\n",
    "\n",
    "To get familiar with this machine learning approach, we'll work with a dataset on sold houses in Ames, Iowa. Each row in the dataset describes the properties of a single house as well as the amount it was sold for. In this course, we'll build models that predict the final sale price from its other attributes. Specifically, we'll explore the following questions:\n",
    "\n",
    "Which properties of a house most affect the final sale price?\n",
    "How effectively can we predict the sale price from just its properties?\n",
    "This dataset was originally compiled by Dean De Cock for the primary purpose of having a high quality dataset for regression. You can read more about his process and motivation here and download the dataset here [https://ww2.amstat.org/publications/jse/v19n3/decock/AmesHousing.txt].\n",
    "\n",
    "Here are some of the columns:\n",
    "\n",
    "Lot Area: Lot size in square feet.\n",
    "Overall Qual: Rates the overall material and finish of the house.\n",
    "Overall Cond: Rates the overall condition of the house.\n",
    "Year Built: Original construction date.\n",
    "Low Qual Fin SF: Low quality finished square feet (all floors).\n",
    "Full Bath: Full bathrooms above grade.\n",
    "Fireplaces: Number of fireplaces.\n",
    "\n",
    "Let's start by generating train and test datasets and getting more familiar with the data.\n",
    "\n",
    "Instructions\n",
    "Read AmesHousing.txt into a dataframe using the tab delimiter (\\t) and assign to data.\n",
    "Select the first 1460 rows from from data and assign to train.\n",
    "Select the remaining rows from data and assign to test.\n",
    "Use the dataframe.info() method to display information about each column.\n",
    "Read the data documentation [https://ww2.amstat.org/publications/jse/v19n3/decock/DataDocumentation.txt] to get more familiar with each column.\n",
    "Using the data documentation, determine which column is the target column we want to predict. Assign the column name as a string to target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3. Simple Linear Regression\n",
    "\n",
    "We'll start by understanding the univariate case of linear regression, also known as simple linear regression. The following equation is the general form of the simple linear regression model.\n",
    "\n",
    "\n",
    "\n",
    " represents the target column while \n",
    " represents the feature column we choose to use in our model. These values are independent of the dataset. On the other hand, \n",
    " and \n",
    " represent the parameter values that are specific to the dataset. The goal of simple linear regression is to find the optimal parameter values that best describe the relationship between the feature column and the target column. The following diagram shows different simple linear regression models depending on the data:\n",
    "\n",
    "Simple Linear Regression\n",
    "https://s3.amazonaws.com/dq-content/235/simple_linear_regression.svg\n",
    "\n",
    "The first step is to select the feature, \n",
    ", we want to use in our model. Once we select this feature, we can use scikit-learn to determine the optimal parameter values \n",
    " and \n",
    " based on the training data. Because one of the assumptions of linear regression is that the relationship between the feature(s) and the target column is linear, we want to pick a feature that seems like it has the strongest correlation with the final sale price.\n",
    " \n",
    " Instructions\n",
    " Generate 3 scatter plots in the same column:\n",
    "The first plot should plot the Garage Area column on the x-axis against the SalePrice column on the y-axis.\n",
    "The second one should plot the Gr Liv Area column on the x-axis against the SalePrice column on the y-axis.\n",
    "The third one should plot the Overall Cond column on the x-axis against the SalePrice column on the y-axis.\n",
    "Read more about these 3 columns in the data documentation [https://ww2.amstat.org/publications/jse/v19n3/decock/DataDocumentation.txt]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# For prettier plots.\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4. Least Squares\n",
    "\n",
    "From the last screen, we can tell that the Gr Liv Area feature correlates the most with the SalePrice column. We can confirm this by calculating the correlation between pairs of these columns using the pandas.DataFrame.corr() method [https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.corr.html]:\n",
    "\n",
    ">>> train[['Garage Area', 'Gr Liv Area', 'Overall Cond', 'SalePrice']].corr()\n",
    "              Garage Area  Gr Liv Area  Overall Cond  SalePrice\n",
    "Garage Area     1.000000    0.468997     -0.151521    0.623431\n",
    "Gr Liv Area     0.468997    1.000000     -0.079686    0.708624\n",
    "Overall Cond   -0.151521   -0.079686      1.000000    -0.077856\n",
    "SalePrice       0.623431    0.708624      -0.077856    1.000000\n",
    "\n",
    "The correlation between Gr Liv Area and SalePrice is around 0.709, which is the highest. Recall that the closer the correlation coefficient is to 1.0, the stronger the correlation. Here's the updated form of our model:\n",
    "\n",
    "\n",
    "Let's now move on to understanding the model fitting criteria.\n",
    "\n",
    "Residual Sum Of Squares\n",
    "\n",
    "To find the optimal parameters for a linear regression model, we want to optimize the model's residual sum of squares (or RSS). If you call, residual (often referred to as errors) describes the difference between the predicted values for the target column (\n",
    ") and the true values (\n",
    "):\n",
    "\n",
    "Visualizing RSS\n",
    "\n",
    "We want this difference to be as small as possible. Calculating RSS involves summing the squared errors:\n",
    "\n",
    "\n",
    "We can shorten this to:\n",
    "\n",
    "\n",
    "If you recall, the calculation for RSS seems very similar to the calculation for MSE (mean squared error). Here's the formula for MSE, adapted for our new notation:\n",
    "\n",
    "\n",
    "While we used the MSE on the test set, it's clear that the goal of minimizing RSS on the training set when training is a good idea."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "5. Using Scikit-Learn To Train And Predict\n",
    "\n",
    "Let's now use scikit-learn to find the optimal parameter values for our model. The scikit-learn library was designed to easily swap and try different models. Because we're familiar with the scikit-learn workflow for k-nearest neighbors, switching to using linear regression is straightforward.\n",
    "\n",
    "Instead of working with the sklearn.neighbors.KNeighborsRegressors class, we work with the sklearn.linear_model.LinearRegression class. The LinearRegression class also has it's own fit() method. Specific to this model, however, is the coef_ and intercept_ attributes, which return a1\n",
    "(a1 to an if it were a multivariate regression model) and \n",
    " accordingly.\n",
    " \n",
    " Instructions\n",
    " Import and instantiate a linear regression model.\n",
    "Fit a linear regression model that uses the feature and target columns we explored in the last 2 screens. Use the default arguments.\n",
    "Display the coefficient and intercept of the fitted model using the coef_ and intercept_ attributes.\n",
    "Assign a1 to a1 and a0 to a0."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "6. Making Predictions\n",
    "\n",
    "In the last step, we fit a univariate linear regression model between the Gr Liv Area and SalePrice column. We then displayed the single coefficient and the residuel value. If we refer back to the format of our linear regression model, the fitted model can be represented as:\n",
    "\n",
    "\n",
    "One way to interpret this model is \"for every 1 square foot increase in above ground living area, we can expect the home's value to increase by approximately 116.87 dollars\".\n",
    "\n",
    "We can now use the predict() method to predict the labels using the training data and compare them with the actual labels. To quantify the fit, we can use mean squared error. Let's also perform simple validation by making predictions on the test set and calculate the MSE value for those predictions as well.\n",
    "\n",
    "Instructions\n",
    "Use the fitted model to make predictions on both the training and test sets.\n",
    "Calculate the RMSE value for the predictions on the training set and assign to train_rmse.\n",
    "Calculate the RMSE value for the predictions on the test set and assign to test_rmse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(train[['Gr Liv Area']], train['SalePrice'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "7. Multiple Linear Regression\n",
    "\n",
    "Now that we've explored the basics of simple linear regression, we can extend what we've learned to the multivariate case (often called multiple linear regression). A multiple linear regression model allows us to capture the relationship between multiple feature columns and the target column. Here's what the formula looks like:\n",
    "\n",
    "\n",
    "When using multiple features, the main challenge is selecting relevant features. In a later mission in this course, we'll dive into some approaches for feature selection. For now, let's train a model using the following columns from the dataset to see how train and test RMSE values are improved.\n",
    "\n",
    "Overall Cond\n",
    "Gr Liv Area\n",
    "\n",
    "Instructions\n",
    "Train a linear regression model using the columns in cols.\n",
    "Use the fitted model to make predictions on both the training and test dataset.\n",
    "Calculate the RMSE value for the predictions on the training set and assign to train_rmse_2.\n",
    "Calculate the RMSE value for the predictions on the training set and assign to test_rmse_2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['Overall Cond', 'Gr Liv Area']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
